{"componentChunkName":"component---src-templates-blog-template-js","path":"/recoder/","result":{"data":{"cur":{"id":"c22268de-e987-5be4-bcac-d6f9120cc4d8","html":"<h1 id=\"a-syntax-guided-edit-decoder-for-neural-program-repair\" style=\"position:relative;\"><a href=\"#a-syntax-guided-edit-decoder-for-neural-program-repair\" aria-label=\"a syntax guided edit decoder for neural program repair permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>A Syntax-Guided Edit Decoder for Neural Program Repair</h1>\n<p><strong>Qihao Zhu</strong>\nKey Laboratory of HCST, MoE DCST, Peking University Beijing, China <a href=\"mailto:Zhuqh@pku.edu.cn\">Zhuqh@pku.edu.cn</a></p>\n<p><strong>Zeyu Sun</strong>\nKey Laboratory of HCST, MoE DCST, Peking University Beijing, China <a href=\"mailto:szy_@pku.edu.cn\">szy_@pku.edu.cn</a></p>\n<p><strong>Yuan-an Xiao</strong>\nKey Laboratory of HCST, MoE DCST, Peking University Beijing, China <a href=\"mailto:xiaoyuanan@pku.edu.cn\">xiaoyuanan@pku.edu.cn</a></p>\n<p><strong>Wenjie Zhang</strong>\nKey Laboratory of HCST, MoE DCST, Peking University Beijing, China <a href=\"mailto:zhang_wen_jie@pku.edu.cn\">zhang_wen_jie@pku.edu.cn</a></p>\n<p><strong>Kang Yuan</strong>\nStony Brook University New York, US <a href=\"mailto:kang.yuan@stonybrook.edu\">kang.yuan@stonybrook.edu</a></p>\n<p><strong>Yingfei Xiong</strong></p>\n<p>Key Laboratory of HCST, MoE DCST, Peking University Beijing, China <a href=\"mailto:xiongyf@pku.edu.cn\">xiongyf@pku.edu.cn</a></p>\n<p><strong>Lu Zhang</strong>\nKey Laboratory of HCST, MoE DCST, Peking University Beijing, China <a href=\"mailto:zhanglucs@pku.edu.cn\">zhanglucs@pku.edu.cn</a></p>\n<p><strong>KEYWORDS</strong></p>\n<p>Automated program repair, Neural networks</p>\n<p><strong>ACM Reference Format:</strong></p>\n<p>Qihao Zhu, Zeyu Sun, Yuan-an Xiao, Wenjie Zhang, Kang Yuan, Yingfei Xiong, and Lu Zhang. 2021. A Syntax-Guided Edit Decoder for Neural Program Repair. In Proceedings of the 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engi- neering (ESEC/FSE ’21), August 23–28, 2021, Athens, Greece. ACM, New York, NY, USA, 13 pages. <a href=\"https://doi.org/10.1145/3468264.3468544\">https://doi.org/10.1145/3468264.3468544</a></p>\n<p><a href=\"https://dl.acm.org/doi/abs/10.1145/3468264.3468544?casa_token=7YNel2Xox8EAAAAA:6Exp9p20FNVhkgXEIy-PjW8BoPAF_23tte2da-A5xEXNKNbhGqZ9gGhM_kb5rpF11-wo0nqIng_LHfE\">Link</a></p>\n<h2 id=\"abstract\" style=\"position:relative;\"><a href=\"#abstract\" aria-label=\"abstract permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ABSTRACT</h2>\n<h2 id=\"1-introduction\" style=\"position:relative;\"><a href=\"#1-introduction\" aria-label=\"1 introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. INTRODUCTION</h2>\n<p>DL 기반 APR 접근 방식은 아직 기존 APR 접근 방식을 능가하지 못했습니다.</p>\n<p>우리는 기존의 DL 기반 APR 접근 방식이 APR에 대해 다른 인코더 아키텍처를 제안했지만 디코더 아키텍처가 표준 아키텍처로 남아 원래 결함이 있는 프로그램 조각을 대체하기 위해 토큰 시퀀스를 하나씩 생성한다는 것을 관찰했습니다. 이 표준 디코더를 사용하면 DL 기반 APR의 성능이 크게 제한됩니다. 여기서 우리는 세 가지 주요 제한 사항을 강조합니다.</p>\n<h3 id=\"limitation-1-including-syntactically-incorrect-programs-in-the-patch-space\" style=\"position:relative;\"><a href=\"#limitation-1-including-syntactically-incorrect-programs-in-the-patch-space\" aria-label=\"limitation 1 including syntactically incorrect programs in the patch space permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Limitation 1: Including syntactically incorrect programs in the patch space.</h3>\n<h3 id=\"limitation-2-inefficient-representation-of-small-edits\" style=\"position:relative;\"><a href=\"#limitation-2-inefficient-representation-of-small-edits\" aria-label=\"limitation 2 inefficient representation of small edits permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Limitation 2: Inefficient representation of small edits.</h3>\n<h3 id=\"limitation-3-not-being-able-to-generate-project-specific-identifiers\" style=\"position:relative;\"><a href=\"#limitation-3-not-being-able-to-generate-project-specific-identifiers\" aria-label=\"limitation 3 not being able to generate project specific identifiers permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Limitation 3: Not being able to generate project-specific identifiers.</h3>\n<h3 id=\"novelty-1-syntax-guided-edit-decoding-with-providerdecider-architecture\" style=\"position:relative;\"><a href=\"#novelty-1-syntax-guided-edit-decoding-with-providerdecider-architecture\" aria-label=\"novelty 1 syntax guided edit decoding with providerdecider architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Novelty 1: Syntax-Guided Edit Decoding with Provider/Decider Architecture</h3>\n<h3 id=\"novelty-2-placeholder-generation\" style=\"position:relative;\"><a href=\"#novelty-2-placeholder-generation\" aria-label=\"novelty 2 placeholder generation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Novelty 2: Placeholder Generation</h3>\n<h2 id=\"2-edits\" style=\"position:relative;\"><a href=\"#2-edits\" aria-label=\"2 edits permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. EDITS</h2>\n<p>The syntax and semantic of edits and their relations to providers</p>\n<h3 id=\"21-syntax-and-semantics-of-edits\" style=\"position:relative;\"><a href=\"#21-syntax-and-semantics-of-edits\" aria-label=\"21 syntax and semantics of edits permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.1 Syntax and Semantics of Edits</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 73.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABYlAAAWJQFJUiTwAAABw0lEQVQ4y3WTh47DQAhE9/8/LUrvvTcrUXpvnB7S+OxTDomss4aBGXD4fD72er1st9vZ5XIxjDv8/X7b/X73d9vt1k6nk12vV7vdbnFcMh4LPByPR8vn8zabzVKB5/PZNpuNlUolazabVqlUrFwuO6hMYCnA/X5vjUbDlstlCvBwOHixVqtlk8nEgSk8Ho9tOBx6sSSwA/LDCwCz2WyKDhJAF6BOp+OFoU0hTuTAkEY5wRL2fD7tr3FXq9W8YK/Xs3a77R3zjAyDwcCq1Wqsv1MmiQtVhyadisZ0OnV9deLQxheLhZ/kxYCIj37JALoicbVaeTB0oY9TkKlzJ+c/1IP9Y+v12gEZBuBoyJShx1koFJw6z/V63Yf1eDx+OyS53++7NnQo/ZCBRCVRILmXGhRdxx0yLS4VSFByyuqIIQAYRZEXRVNcm+EaauTfTEOhIM4XRddQA0RfDRha7oBW0CkWi67VfD53naCZyWT8jlVBDmKIZanplmdpmcvlnFlgqQnsdruezF7hBLPQUEPf0Wjk94BBm/8MCkd3TmQLrARgSiJYy8sys0baTQ0BDaEKfdHV+XVtRJuTjgBXAQpCk/38Zj/aMmuRfkqwMQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"figure4.png\"\n        title=\"figure4.png\"\n        src=\"/static/5afead6a057be132bc80e1e81b5101e3/37523/figure4.png\"\n        srcset=\"/static/5afead6a057be132bc80e1e81b5101e3/e9ff0/figure4.png 180w,\n/static/5afead6a057be132bc80e1e81b5101e3/f21e7/figure4.png 360w,\n/static/5afead6a057be132bc80e1e81b5101e3/37523/figure4.png 720w,\n/static/5afead6a057be132bc80e1e81b5101e3/302a4/figure4.png 1080w,\n/static/5afead6a057be132bc80e1e81b5101e3/105d8/figure4.png 1170w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<ul>\n<li>Host language : 별도의 소프트웨어가 설치되어 있지 않은 컴퓨터에서도 사용할 수 있는 프로그래밍 언어. 일반적으로 컴퓨터에서 사용되는 기계어가 이에 해당한다고 할 수 있지만, 몇몇 컴퓨터에서는 운영 체제에서 지원하는 고급 언어를 이 언어로 제공하고 있다.</li>\n<li>Non-terminal symbol : &#x3C;>로 둘러쌓인 기호를 논터미널 기호라고 부른다.</li>\n</ul>\n<p>Recoder는 특정 프로그래밍이 아닌 모든 프로그래밍 언어에 적용할 수 있다. (Host Language)</p>\n<p><strong>Rule 1</strong></p>\n<ul>\n<li>Edits은 Edits, Edit, end가 될 수 있다.</li>\n</ul>\n<p><strong>Rule 2</strong></p>\n<ul>\n<li>Edit은 Insert 혹은 Modift operation이다.</li>\n</ul>\n<p><strong>Rule 3</strong> (the syntax of insert operation)</p>\n<ul>\n<li>Insert operation은 faulty statement 앞에 새로운 statement를 생성한다.</li>\n<li>Insert operation has one parameter\n<ul>\n<li>HLStatement\n<ul>\n<li>non-terminal in the grammar of the host language that represents a statement\n<ul>\n<li>Non-terminal could be expanded into a full statement or copy operation</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong>Rule 4</strong> (the syntax of modify operation)</p>\n<ul>\n<li>Modify operation은 faulty statement를 가진 AST subtree를 새로운 AST subtree로 바꾼다.</li>\n<li>Modify operation has two parameter\n<ul>\n<li>First parameter : 교체될 AST subtree로부터의 root node의 ID\n<ul>\n<li>ID는 pre-order traveral sequence의 노드 순서로 정의된다.\n<ul>\n<li>6번째로 방문한 노드는 ID 6</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Second parameter : an AST subtree whose root node has the same symbol\n<ul>\n<li>the replacement ensures syntactic correctness</li>\n<li>the subtree to be replaced should have more than one node</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong>Rule 5</strong></p>\n<ul>\n<li>a meta-rule applied to any non-terminal symbol of the host language.</li>\n<li>add production rule that expands it into a copy operation</li>\n<li>the nueral network could choose to directly gerate a new subtree or to copy one</li>\n<li>For both insert and modify, they generate a new AST subtree\n<ul>\n<li>the AST subtree being inserted or modified is not completely original\n<ul>\n<li>Copy operation is introduced to further reduce the patch space</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>copy operation\n<ul>\n<li>1 parameter identifies the root node of the AST subtree to be copied\n<ul>\n<li>the faulty statement or its context</li>\n<li>method surrounding the faulty statement</li>\n</ul>\n</li>\n<li>the root node of the subtree to be copied should have the same non-terminal symbol as the symbol being extended</li>\n</ul>\n</li>\n</ul>\n<p>**Rule 6 **(placeholder)</p>\n<ul>\n<li>to generate concrete identifiers</li>\n<li>change identifier nodes into non-terminals</li>\n<li>plceholder or one of the frequent identifiers in the training set</li>\n</ul>\n<h3 id=\"23-generation-of-edits\" style=\"position:relative;\"><a href=\"#23-generation-of-edits\" aria-label=\"23 generation of edits permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.3 Generation of Edits</h3>\n<p>Providers : provide choices and estimate their probabilities</p>\n<p>3 type of providers</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 34.44444444444444%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAABYlAAAWJQFJUiTwAAABC0lEQVQoz12R6aqDQAyFff8H85+KiuJW9+IudUXUmnJSRnqvcMgkTk6+mZHo35emKVmWTUVRUBiG5HkexXHM6yRJWEEQkOM4/O+6rj/90nme1Pc9tW3LMcuyW1EUsZEwgzFqGJrnOT2fTxrHkaZpYh3HQRImYKIsy6QoCk99vV5kWRbpuk6GYXAEkaZppKoqm23bRuu60jAMt/Z9/xJigyCq65rmeWYi1EGFdVmW5Ps+C8TIBTWI0f9+v7+G2ASCx+PBZLg/5LZt07IsfBwMAQXoEVETEceG+MgwdF2XjUzTZLOmabiGHNcBgQjmMIbEkN94G+JBYIImMRk5hCuoqoq6rrtpxCP8ShB+APvoCZYgf0ngAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table1.png\"\n        title=\"table1.png\"\n        src=\"/static/4bfd86434d0280fab4b0aa74b8b93eb9/37523/table1.png\"\n        srcset=\"/static/4bfd86434d0280fab4b0aa74b8b93eb9/e9ff0/table1.png 180w,\n/static/4bfd86434d0280fab4b0aa74b8b93eb9/f21e7/table1.png 360w,\n/static/4bfd86434d0280fab4b0aa74b8b93eb9/37523/table1.png 720w,\n/static/4bfd86434d0280fab4b0aa74b8b93eb9/302a4/table1.png 1080w,\n/static/4bfd86434d0280fab4b0aa74b8b93eb9/393aa/table1.png 1190w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p><strong>rule predictor</strong></p>\n<ul>\n<li>선택 사항을 제공하고 각 production rule의 확률을 계산</li>\n<li>Neural component\n<ul>\n<li>각 생성 규칙에 대한 확률을 할당</li>\n</ul>\n</li>\n<li>Logic component\n<ul>\n<li>왼쪽이 해당 non-terminal이 아닌 rule의 확률을 0으로 재설정</li>\n<li>나머지 확률을 정규화</li>\n</ul>\n</li>\n</ul>\n<p><strong>subtree locator</strong></p>\n<ul>\n<li>선택 사항을 제공</li>\n<li>Faulty statement에서 크기가 1보다 큰 각 AST 하위 트리의 확률을 추정</li>\n</ul>\n<p><strong>tree copier</strong></p>\n<ul>\n<li>선택 사항 제공</li>\n<li>Faulty statement를 둘라싼 method의 크기가 1보다 큰 각 AST subtree의 확률을 추정</li>\n<li>neural component</li>\n<li>logic component\n<ul>\n<li>root symbol이 확장되는 non-terminal symbol과 다른 subtree의 확룰을 재설정</li>\n</ul>\n</li>\n</ul>\n<p><strong>decider</strong></p>\n<ul>\n<li>각 provider에 확률을 할당</li>\n<li>similar logic component\n<ul>\n<li>provider가 현재 non-terminal symbol을 담당하지 않을 경우, 확률을 0으로 재설정</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-model-architecture\" style=\"position:relative;\"><a href=\"#3-model-architecture\" aria-label=\"3 model architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3 MODEL ARCHITECTURE</h2>\n<p>Recoder is based on the syntax guided code generation model, <a href=\"https://ojs.aaai.org/index.php/AAAI/article/view/6430\">TreeGen</a></p>\n<p>input : a faulty statement and its comtext</p>\n<p>output : edits</p>\n<p>Beam search (to find the best combination of choices for generating the complete edits)</p>\n<p>4 main component</p>\n<ul>\n<li>code reader</li>\n<li>AST reader</li>\n<li>tree path reader</li>\n<li>Edit decoder</li>\n</ul>\n<p>AST reader, tree path reader : TreeGen</p>\n<p>Code reader, edit decoder : newly introduced</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 32.22222222222222%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAABYlAAAWJQFJUiTwAAABRUlEQVQY0z1RTWvCQBDNH++5v6HY2oLHHrQkMd+fNWmTkEMa2SAoCB7UVASDURDjKzNgB5adefvmzTJPatsWq9UK0+kUy+US+/2eD2FUb7dbXK9XUDRNg+PxiHt0XYfb7cb3PaSiKKBpGkzThOu6iOMYvu/Dsqx/bLFYIIoiBEHAb3meI80yaJoB3TChjjU4roe2PUFK05QbScDzPBbXdR2O4zBGOeGqqmI4HEKWFfiei/7gHQ+PT+g99/HW72Hw+oK6/oWUZRlPpib6xWg0gizLLESCNMC2bYRhyLzvJEEQ+PiQx7D9LxiWgzD8ZM5ut4NUVRWTCTAMgw/VNIAwRVGQJAlo8GQy4RUQnqYJyp+CMSEqCCF4vxItlZL5fI7NZoPL5YLz+cymlGWJ9XrNJtV1zU2z2Yz5zeGAOIpQCcHmEY9M+QN6g5p5TiMDIwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"figure7.png\"\n        title=\"figure7.png\"\n        src=\"/static/592d4ccd9b7044beb668312034b0f6b6/37523/figure7.png\"\n        srcset=\"/static/592d4ccd9b7044beb668312034b0f6b6/e9ff0/figure7.png 180w,\n/static/592d4ccd9b7044beb668312034b0f6b6/f21e7/figure7.png 360w,\n/static/592d4ccd9b7044beb668312034b0f6b6/37523/figure7.png 720w,\n/static/592d4ccd9b7044beb668312034b0f6b6/302a4/figure7.png 1080w,\n/static/592d4ccd9b7044beb668312034b0f6b6/07a9c/figure7.png 1440w,\n/static/592d4ccd9b7044beb668312034b0f6b6/4a70a/figure7.png 2390w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3 id=\"31-code-reader\" style=\"position:relative;\"><a href=\"#31-code-reader\" aria-label=\"31 code reader permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.1 Code Reader</h3>\n<p>input</p>\n<ul>\n<li>AST traversal sequence\n<ul>\n<li>a sequence of tokens following the pre-order traversal of the AST</li>\n<li>word embedding</li>\n</ul>\n</li>\n<li>Tag embedding\n<ul>\n<li>Pre-order traversal of the AST</li>\n<li>tag\n<ol>\n<li>in the faulty statement</li>\n<li>In the statement before the faulty statement</li>\n<li>In the statement after the faulty statement</li>\n<li>in other statements</li>\n</ol>\n</li>\n</ul>\n</li>\n<li>AST-based Graph\n<ul>\n<li>directional graph where the nodes are AST nodes and the edges link a node to each of its children and its sibling</li>\n<li><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 38.888888888888886%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAABMklEQVQoz31Ra4+CQAzk//8vEEMiMchbI6DyUCQ+QA0Exkwv68UPd5s0dOnsdDrVpmkCT9d1uF6vuN1uuN/vEuM4So0YhXs+n1845sMwfHCaAmZZBl3XMZvNJDzPE6Cqq9M0DebzOQzDgGmaWCwWaNv2l5AAx3Hg+z7KsoTrutjtdhJBEKCuaxRFIbXtdgvbtuW7Xq8RhiGSJBFcnuciQOMDgqjwdDoJ4eFwECLmBHJMqiABm7MWxzGiKBLFzBlCeD6fsVqtkKYpqqqCHwTY7/dCtFwupZHyjgS04ng8isLNZiPknI4qhRB/HDYiiKr/O1wmm5C87/ufpSjjL5eLeMLNKRX0kneORjUM5vxPb1+vl9S58c+WFSGNtyxLTOcDjsKxaQcV8E4fqVwt6PF4fCl+Az8tVqpYcGPXAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"figure8.png\"\n        title=\"figure8.png\"\n        src=\"/static/d4383fd3c116d749d45bacf6e9816fc7/37523/figure8.png\"\n        srcset=\"/static/d4383fd3c116d749d45bacf6e9816fc7/e9ff0/figure8.png 180w,\n/static/d4383fd3c116d749d45bacf6e9816fc7/f21e7/figure8.png 360w,\n/static/d4383fd3c116d749d45bacf6e9816fc7/37523/figure8.png 720w,\n/static/d4383fd3c116d749d45bacf6e9816fc7/302a4/figure8.png 1080w,\n/static/d4383fd3c116d749d45bacf6e9816fc7/df56e/figure8.png 1188w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"311-self-attention\" style=\"position:relative;\"><a href=\"#311-self-attention\" aria-label=\"311 self attention permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.1.1 Self-Attention</h4>\n<ul>\n<li>self-attention sub-layer\n<ul>\n<li>encoding the AST traversal sequence</li>\n<li><a href=\"https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html\">Transformer</a> architecture\n<ul>\n<li>Capture the long dependency information in the AST</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Position embedding (represent positional information)</li>\n<li>multi-head attention layer\n<ul>\n<li>capture non-linear features</li>\n<li>The single attention layer maps the query Q, the key K, and the value V into a weighted-sum output</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"312-gating-layer\" style=\"position:relative;\"><a href=\"#312-gating-layer\" aria-label=\"312 gating layer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.1.2 Gating Layer</h4>\n<ul>\n<li>input : self-attention 레이어의 아웃풋 + 태그 임베딩</li>\n<li>TreeGen에서 정의된 Gating mechanism이 이 레이어에서 사용되었다.</li>\n</ul>\n<h4 id=\"313-tree-conv-layer\" style=\"position:relative;\"><a href=\"#313-tree-conv-layer\" aria-label=\"313 tree conv layer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.1.3 Tree Conv Layer</h4>\n<ul>\n<li>\n<p>input : gating layer의 아웃풋 + AST-based graph</p>\n</li>\n<li>\n<p>GNN layer</p>\n</li>\n<li>\n<p>encode the neighbors</p>\n</li>\n</ul>\n<h3 id=\"32-ast-reader\" style=\"position:relative;\"><a href=\"#32-ast-reader\" aria-label=\"32 ast reader permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.2 AST Reader</h3>\n<ul>\n<li>Encode the partial generated AST of the edit (TreeGen)</li>\n<li>Rule requence\n<ul>\n<li>represented as real-value vectors</li>\n<li>fed into a self-attention layer</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"33-tree-path-reader\" style=\"position:relative;\"><a href=\"#33-tree-path-reader\" aria-label=\"33 tree path reader permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.3 Tree Path Reader</h3>\n<ul>\n<li>Encode the information of the non-terminal node to be expanded (TreeGen)</li>\n<li>Represent the non-terminal node as a path from the root to the node to be expanded</li>\n<li>Transforms the nodes in this path into real-value vectors</li>\n<li>Two fully-connected layers are followed to extract features for edit decoder</li>\n</ul>\n<h3 id=\"34-edit-decoder\" style=\"position:relative;\"><a href=\"#34-edit-decoder\" aria-label=\"34 edit decoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.4 Edit Decoder</h3>\n<p>Input : tree path reader의 아웃풋</p>\n<p>output : the probability of choices for diferent non-terminals</p>\n<h4 id=\"341-provider\" style=\"position:relative;\"><a href=\"#341-provider\" aria-label=\"341 provider permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.4.1 Provider</h4>\n<p><strong>Rule Predictor</strong></p>\n<ul>\n<li>Estimate the probability of each production rule in the grammar of edits</li>\n<li>Nueral component (a fully-connected layer)</li>\n<li>Normalized via softmax</li>\n<li>Invalid rules whose left-hand side is not the corresponding non-terminal are not allowed</li>\n<li>The logic component resets the output of the fully-connected layer to -∞.</li>\n</ul>\n<p><strong>Tree Copier</strong></p>\n<ul>\n<li>Designed for any non-terminal symbol in the grammer of edits to choose a subtree in the local context</li>\n<li>Nueral component (a pointer network)</li>\n<li>The logic component resets  𝜽 to −∞ if the root symbol of the corresponding subtree is different from the symbol being expanded.</li>\n<li>Normalized via softmax</li>\n</ul>\n<p><strong>Subtree Locator</strong></p>\n<p>output : an ID of the subtree in the faulty statement for not-terminal symbol, Modify, in the grammar of edits.</p>\n<h4 id=\"342-decider\" style=\"position:relative;\"><a href=\"#342-decider\" aria-label=\"342 decider permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.4.2 Decider</h4>\n<ul>\n<li>Estimate the probability of using each provider</li>\n<li>Neural component\n<ul>\n<li>input : the output of the tree path reader</li>\n<li>output : the probability of using each provider</li>\n<li>A fully-connected layer</li>\n</ul>\n</li>\n<li>Logic component resets 𝝀 to −∞ if the corresponding provider is not responsible for the symbol being expanded following Table 1.</li>\n<li>Normalized via softmax</li>\n</ul>\n<h3 id=\"35-training-and-inference\" style=\"position:relative;\"><a href=\"#35-training-and-inference\" aria-label=\"35 training and inference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.5 Training and Inference</h3>\n<h3 id=\"36-patch-generation-and-validation\" style=\"position:relative;\"><a href=\"#36-patch-generation-and-validation\" aria-label=\"36 patch generation and validation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.6 Patch Generation and Validation</h3>","excerpt":"A Syntax-Guided Edit Decoder for Neural Program Repair Qihao Zhu\nKey Laboratory of HCST, MoE DCST, Peking University Beijing, China Zhuqh@pku.edu.cn Zeyu Sun\nKey Laboratory of HCST, MoE DCST, Peking University Beijing, China szy_@pku.edu.cn Yuan-an Xiao\nKey Laboratory of HCST, MoE DCST, Peking University Beijing, China xiaoyuanan@pku.edu.cn Wenjie Zhang\nKey Laboratory of HCST, MoE DCST, Peking University Beijing, China zhang_wen_jie@pku.edu.cn Kang Yuan\nStony Brook University New York, US kang.…","frontmatter":{"date":"August 03, 2023","title":"Recoder (A Syntax-guided Edit Decoder for Neural Program Repair)","categories":"APR featured","author":"DolmaengC","emoji":"🧢"},"fields":{"slug":"/recoder/"}},"next":{"id":"fb46d56b-d700-5a53-895c-233ea069b00c","html":"<h1 id=\"treegen-a-tree-based-transformer-architecture-for-code-generation\" style=\"position:relative;\"><a href=\"#treegen-a-tree-based-transformer-architecture-for-code-generation\" aria-label=\"treegen a tree based transformer architecture for code generation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TreeGen: A Tree-Based Transformer Architecture for Code Generation</h1>\n<p>**Zeyu Sun† **</p>\n<p>**Qihao Zhu† **</p>\n<p>**Yingfei Xiong∗† **</p>\n<p>**Yican Sun† Lili Mou‡ **</p>\n<p><strong>Lu Zhang†</strong></p>\n<h2 id=\"abstrct\" style=\"position:relative;\"><a href=\"#abstrct\" aria-label=\"abstrct permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ABSTRCT</h2>\n<p>코드 생성 시스템은 자연어 묘사를 인풋으로 프로그래밍 언어 코드를 생성한다.</p>\n<p>최신 기술들은 뉴럴 네트워크에 의존하는데 , 2가지 문제점이 있다.</p>\n<ol>\n<li>긴 의존성 문제\n<ul>\n<li>코드는 종종 멀리있는 코드 요소의 영향을 받는다.</li>\n</ul>\n</li>\n<li>모델링 구조\n<ul>\n<li>많은 구조적 정보를 가지고 있다.</li>\n</ul>\n</li>\n</ol>\n<p>TreeGen : 새로운 트리 기반 뉴럴 구조 (트렌스포머의 어텐션 메커니즘을 사용)</p>\n<p>벤치마크</p>\n<ul>\n<li>파이썬 벤치마크 : HearthStone</li>\n<li>semantic parsing 벤치마크 : ATIS, GEO</li>\n</ul>\n<h1 id=\"introduction\" style=\"position:relative;\"><a href=\"#introduction\" aria-label=\"introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>INTRODUCTION</h1>\n<p>코드 생성은 개발자들의 생산성을 향상시키기 위한 중요한 인공지능이다.</p>\n<p>Seq2Seq, Seq2Tree 모델 등 다양한 신경망 구조를 갖는다.</p>\n<p>최신 접근법은 문법 규칙의 sequence를 예측하는 코드를 생성하는 것이다.</p>\n<p>이 논문은 새로운 신경망 구조 (TreeGen)을 제안한다.</p>\n<p>TreeGen은 트렌스포머 구조를 제안하지만, 기존의 트렌스포머는 프로그램용으로 설계되어 있지 않았으며,</p>\n<p>트리 구조에 최적화 되어 있지 않다.</p>\n<p>최적화를 위해서는 그래프, 트리 기반의 컨볼루션 신경망 구조를 가져야 한다.</p>\n<p>TreeGen은 3부분으로 구성한다.</p>\n<ol>\n<li>\n<p>A natural language reader (encoder) : encode the text description.</p>\n</li>\n<li>\n<p>A AST reader (the first several transformer decoder blocks) :</p>\n<p>encode the previously generated partial code with the structural convolution sub-layers</p>\n</li>\n<li>\n<p>A decoder (the rest transformer decoder blocks) :</p>\n<p>combine the query and previous two encoders to predict the next grammer rule.</p>\n</li>\n</ol>\n<h2 id=\"treegen\" style=\"position:relative;\"><a href=\"#treegen\" aria-label=\"treegen permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TreeGen</h2>\n<p>![스크린샷 2023-08-01 오후 2.22.20](/Users/choejunhyeog/Desktop/스크린샷 2023-08-01 오후 2.22.20.png)</p>\n<h3 id=\"1-grammar-rule-prediction\" style=\"position:relative;\"><a href=\"#1-grammar-rule-prediction\" aria-label=\"1 grammar rule prediction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Grammar Rule Prediction</h3>\n<p>decomposed into several context-free grammar rules and parsed as an AST</p>\n<p>AST-based code generation could be thought of as expanding a non-terminal node by a grammar rule. This process is repeated until all leaf nodes are terminal.</p>\n<p>선주문 트래버스에 따라 오른쪽 상단 모서리에 표시된 AST를 생성하는 일련의 규칙을 얻을 수 있습니다.</p>\n<p>Formally, the probability can be factorized as the proba- bilities of the rules generating the code following the order.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 9.444444444444445%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAZ0lEQVQI101M2wpAERD0/9/mCzyRyCUKJSRz2n06U9vONBeRUkIIATln7L0hpYQxBucckNdag7WWudaa9VoL7z3MOZnTJ9CO8N7DOceF/2ApBeT13jlIGaUUaq0YY+Deyx4daUKMER+TypbH1ZfKIgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"1.png\"\n        title=\"1.png\"\n        src=\"/static/f55283156537a0436bd2e7ecaa41f66d/37523/1.png\"\n        srcset=\"/static/f55283156537a0436bd2e7ecaa41f66d/e9ff0/1.png 180w,\n/static/f55283156537a0436bd2e7ecaa41f66d/f21e7/1.png 360w,\n/static/f55283156537a0436bd2e7ecaa41f66d/37523/1.png 720w,\n/static/f55283156537a0436bd2e7ecaa41f66d/302a4/1.png 1080w,\n/static/f55283156537a0436bd2e7ecaa41f66d/5f652/1.png 1302w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>our task is to train a model to calculate p(ri | NL input, pi )</p>\n<h3 id=\"2-nl-reader\" style=\"position:relative;\"><a href=\"#2-nl-reader\" aria-label=\"2 nl reader permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. NL Reader</h3>\n<p>The input description determines the functionality of the code.</p>\n<ol>\n<li>Tokenize input description into tokens.</li>\n<li>All the tokens and characters are represented as real-valued vectors n1, n2,…,nL and c1, c2, … , cs by embeddings.</li>\n</ol>\n<p>In summary, the NL reader has a few Transformer blocks</p>\n<p>of self-attention, the gating mechanism, and word convolu-</p>\n<p>tion. The natural language description is encoded as features y(NL), y(NL), · · · , y(NL).</p>\n<h3 id=\"3-input-text-representation\" style=\"position:relative;\"><a href=\"#3-input-text-representation\" aria-label=\"3 input text representation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Input Text Representation</h3>\n<h4 id=\"character-embedding\" style=\"position:relative;\"><a href=\"#character-embedding\" aria-label=\"character embedding permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Character Embedding</h4>\n<p>Similar words have similar characters (e.g. “program” and “programs”)</p>\n<p>a token by character embeddings with <strong>a fully-connected layer</strong></p>\n<p>![스크린샷 2023-08-01 오후 5.37.43](/Users/choejunhyeog/Desktop/스크린샷 2023-08-01 오후 5.37.43.png)</p>\n<p>W(c) are the weights and the character sequence is padded to a pre-defined maximum length M.</p>\n<p><strong>Layer normalization</strong></p>\n<p>이 벡터들은 NL reader로 넘어가고 <strong>gating sub-layer</strong>에서 워드 임베딩과 통합된다.</p>\n<h3 id=\"4-neural-structure-of-nl-reader\" style=\"position:relative;\"><a href=\"#4-neural-structure-of-nl-reader\" aria-label=\"4 neural structure of nl reader permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. Neural Structure of NL Reader</h3>\n<p>The NL reader is composed of a stack of blocks.</p>\n<p>Each block contains three different sub-layers (self-attention, gating mechanism, word convolution)</p>\n<h4 id=\"self-attention\" style=\"position:relative;\"><a href=\"#self-attention\" aria-label=\"self attention permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Self-Attention</h4>\n<p>Transformer’s architecture</p>\n<p>Multi-head attention (to capture long dependency information)</p>\n<ol>\n<li>Embedding by a look-up table</li>\n<li>position embeddings</li>\n<li>Variant (Dehghani et al.)[<a href=\"https://arxiv.org/abs/1807.03819\">https://arxiv.org/abs/1807.03819</a>]</li>\n<li>Compute the position embedding for the 4th word in the word in the bth Transformer block as</li>\n</ol>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 16.666666666666664%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAl0lEQVQI1z2P0QqFIBBE/f/vK0GsyKxIrSyoh6KY2OFyhUV0Zs/OKvzOuq7w3qOqKuz7jhACrLWIMVJzzqHrOpRliaIoqIv/vm/255zRti3U+76QmqYJKSUCzvMktO973sdxECCaQAW+bRv/nuchUDyiKyE3TUPTPM+ctCwLxnGEMYYmect0SSQJtdZMPQwDruv6b1jXNT7N5eCnGOZARQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"34.png\"\n        title=\"34.png\"\n        src=\"/static/bd49c69e3c7fa5ba9ee0bff0e21393db/37523/34.png\"\n        srcset=\"/static/bd49c69e3c7fa5ba9ee0bff0e21393db/e9ff0/34.png 180w,\n/static/bd49c69e3c7fa5ba9ee0bff0e21393db/f21e7/34.png 360w,\n/static/bd49c69e3c7fa5ba9ee0bff0e21393db/37523/34.png 720w,\n/static/bd49c69e3c7fa5ba9ee0bff0e21393db/302a4/34.png 1080w,\n/static/bd49c69e3c7fa5ba9ee0bff0e21393db/1132d/34.png 1158w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h4 id=\"gating-mechanism\" style=\"position:relative;\"><a href=\"#gating-mechanism\" aria-label=\"gating mechanism permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Gating Mechanism</h4>\n<p>Self-attention에 의해 특징들이 계산된 후에, character 임베딩 정보와 통합한다.</p>\n<p>gating mechanism은 softmax를 베이스로 한다.</p>\n<h4 id=\"word-convolution\" style=\"position:relative;\"><a href=\"#word-convolution\" aria-label=\"word convolution permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Word Convolution</h4>\n<p>2개의 컨볼루션 레이어가 gating 메카니즘의 아웃풋에 적용된다.</p>\n<p>여기서 seperable convolution이 사용된다.</p>\n<ul>\n<li>seperable convolution은 파라미터가 적어서 학습이 쉽다.</li>\n</ul>\n<p>첫번째와 마지막 단어를 위해 zero padding을 추가한다.</p>\n<p>GELU 활성화 함수 사용</p>\n<h3 id=\"5-ast-reader\" style=\"position:relative;\"><a href=\"#5-ast-reader\" aria-label=\"5 ast reader permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. AST Reader</h3>\n<p>생성된 부분적 AST의 구조를 모델링하기 위해 AST reader를 만들었다.</p>\n<p>문법 규칙의 순서를 예측하여 생성하지만, 이 규칙들만으로는 프로그램에 대한 구체적인 그림이 부족하고 다음 규칙을 예측하기에는 불충분하다.</p>\n<p>-> AST reader가 예측된 정보와 트리구조를 포함한 heterogeneous 정보를 고려한다.</p>\n<p>이러한 프로그램별 정보를 통합하기 위해 먼저 코드를 일련의 규칙으로 표현한 다음 어텐션 메커니즘으로 규칙을 인코딩하고 마지막으로 트리 컨볼루션 레이어를 사용하여 각 노드의 인코딩된 표현을 조상과 결합합니다.</p>\n<h3 id=\"6-ast-representation\" style=\"position:relative;\"><a href=\"#6-ast-representation\" aria-label=\"6 ast representation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>6. AST Representation</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 27.77777777777778%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAABYlAAAWJQFJUiTwAAAA/0lEQVQY01VQ6YqGMAz0/V9tBVlR8frhjda23gjqfrNMwIUVxjRpMpOpE4YhCKUU5nnGNE2w1sq573tkWYZ1XVFVFYIgQFmW2LZNasuy/Js5jgMOGzjUti26rvvDOI5CmOe5xKIo4Pu+IE1TRFEk4CLDMKBpGhFw3kGCF2/k9zyPkHML1pIkwevI8zzEcSxnCvCefQ6Tt4m2SEg1Wtj3XTanJda4HYlc9wtZlgp8/xuu64rwfd9wjDHQWos6Fd8NCdphzljXtdhPkhxxnGEYNJSyGEcLpbTYva4LDn8kZYH2CebckCAZBY0hZhhzwtoTxhxQaofWO7btxOfzI0/0CwXHu1deAv0BAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"production-rule\"\n        title=\"production-rule\"\n        src=\"/static/e7b5cc0bc11ac5d28122b7c329270c0d/37523/production-rule.png\"\n        srcset=\"/static/e7b5cc0bc11ac5d28122b7c329270c0d/e9ff0/production-rule.png 180w,\n/static/e7b5cc0bc11ac5d28122b7c329270c0d/f21e7/production-rule.png 360w,\n/static/e7b5cc0bc11ac5d28122b7c329270c0d/37523/production-rule.png 720w,\n/static/e7b5cc0bc11ac5d28122b7c329270c0d/302a4/production-rule.png 1080w,\n/static/e7b5cc0bc11ac5d28122b7c329270c0d/07a9c/production-rule.png 1440w,\n/static/e7b5cc0bc11ac5d28122b7c329270c0d/c679a/production-rule.png 2460w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p><strong>Rule Sequence Embedding</strong></p>\n<ul>\n<li>규칙 정보를 인코딩하기 위해서 규칙 ID를 사용한다.</li>\n<li>규칙들을 table-lookup 임베딩으로 real-valued vectors로 나타낸다.</li>\n</ul>\n<p><strong>Rule Definition Encoding</strong></p>\n<ul>\n<li>위의 테이블 조회 임베딩은 문법 규칙을 원자 토큰으로 취급하고 규칙 내용의 정보를 잃습니다.</li>\n<li>이 문제를 완화하기 위해 규칙 정의의 인코딩으로 규칙 표현을 향상시킵니다.</li>\n</ul>\n<p><strong>Position and Depth Embeddings</strong></p>\n<p>Position embedding</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 8.333333333333332%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAcUlEQVQI11WOuwoFIRBD9/+/zkIr8Y2yCiKKiIWYixYXdqpDksnM473HGAMpJbTWUGuFtRbOucu9dxhjEGOEUgqEEDDGIKX863tvnFlr4TniWXzf9xbmnME5hxDicikFWmucwydLKb3enPM+EkL4FP4AKMyVjwqm6GgAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"4.png\"\n        title=\"4.png\"\n        src=\"/static/0597f682568693ed51f875d060c15793/37523/4.png\"\n        srcset=\"/static/0597f682568693ed51f875d060c15793/e9ff0/4.png 180w,\n/static/0597f682568693ed51f875d060c15793/f21e7/4.png 360w,\n/static/0597f682568693ed51f875d060c15793/37523/4.png 720w,\n/static/0597f682568693ed51f875d060c15793/302a4/4.png 1080w,\n/static/0597f682568693ed51f875d060c15793/b490f/4.png 1142w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3 id=\"7-neural-structure-of-ast-reader\" style=\"position:relative;\"><a href=\"#7-neural-structure-of-ast-reader\" aria-label=\"7 neural structure of ast reader permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>7. Neural Structure of AST Reader</h3>\n<p>four sub-layers (self-attention, gating mechanism, NL attention, tree convolution)</p>\n<p>residual connection except the layer of tree convolution</p>\n<p>layer normalization</p>\n<p><strong>Self-Attention</strong></p>\n<p>Transformer-like self-attention layer</p>\n<p>input : sum of the rule embedding, position embedding, dept embedding</p>\n<p>extract features</p>\n<p><strong>Gating Mechanism</strong></p>\n<p>Content-encoding rule representation</p>\n<p>Transformer-extracted features</p>\n<p><strong>NL Attention</strong></p>\n<p>Multi-head NL attention (similar to the Transformer decoder’s attention to its encoder)</p>\n<p><strong>Tree Convolution</strong></p>\n<h3 id=\"8-decoder\" style=\"position:relative;\"><a href=\"#8-decoder\" aria-label=\"8 decoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>8. Decoder</h3>\n<h3 id=\"9-training-and-inference\" style=\"position:relative;\"><a href=\"#9-training-and-inference\" aria-label=\"9 training and inference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>9. Training and Inference</h3>","frontmatter":{"date":"August 02, 2023","title":"TreeGen","categories":"DL","author":"DolmaengC","emoji":"🧢"},"fields":{"slug":"/TreeGen/"}},"prev":{"id":"df6cd450-36e4-5e66-bfcd-7b78cacb52dc","html":"<h1 id=\"i-gbs\" style=\"position:relative;\"><a href=\"#i-gbs\" aria-label=\"i gbs permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>I-GBS</h1>\n<h2 id=\"본문-누가복음-15장\" style=\"position:relative;\"><a href=\"#%EB%B3%B8%EB%AC%B8-%EB%88%84%EA%B0%80%EB%B3%B5%EC%9D%8C-15%EC%9E%A5\" aria-label=\"본문 누가복음 15장 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>[본문] 누가복음 15장</h2>\n<p><a href=\"https://www.bskorea.or.kr/bible/korbibReadpage.php?linkBible=BGAEluk015001\">bible link</a></p>\n<p><strong>잃은 양을 찾은 목자 비유(마 18:12-14)</strong></p>\n<p>1  모든 세리와 죄인들이 말씀을 들으러 가까이 나아오니\n2  바리새인과 서기관들이 수군거려 이르되 이 사람이 죄인을 영접하고 음식을 같이 먹는다 하더라\n3  예수께서 그들에게 이 비유로 이르시되\n4  너희 중에 어떤 사람이 양 백 마리가 있는데 그 중의 하나를 잃으면 아흔아홉 마리를 들에 두고 그 잃은 것을 찾아내기까지 찾아다니지 아니하겠느냐\n5  또 찾아낸즉 즐거워 어깨에 메고\n6  집에 와서 그 벗과 이웃을 불러 모으고 말하되 나와 함께 즐기자 나의 잃은 양을 찾아내었노라 하리라\n7  내가 너희에게 이르노니 이와 같이 죄인 한 사람이 회개하면 하늘에서는 회개할 것 없는 의인 아흔아홉으로 말미암아 기뻐하는 것보다 더하리라</p>\n<p><strong>잃은 드라크마를 찾은 여인 비유</strong></p>\n<p>8  어떤 여자가 열 <a href=\"https://www.bskorea.or.kr/bible/korbibReadpage.php?linkBible=BGAEluk015001#\">1)</a>드라크마가 있는데 하나를 잃으면 등불을 켜고 집을 쓸며 찾아내기까지 부지런히 찾지 아니하겠느냐\n9  또 찾아낸즉 벗과 이웃을 불러 모으고 말하되 나와 함께 즐기자 잃은 <a href=\"https://www.bskorea.or.kr/bible/korbibReadpage.php?linkBible=BGAEluk015001#\">1)</a>드라크마를 찾아내었노라 하리라\n10  내가 너희에게 이르노니 이와 같이 죄인 한 사람이 회개하면 하나님의 사자들 앞에 기쁨이 되느니라</p>\n<p><strong>잃은 아들을 되찾은 아버지 비유</strong></p>\n<p>11  또 이르시되 어떤 사람에게 두 아들이 있는데\n12  그 둘째가 아버지에게 말하되 아버지여 재산 중에서 내게 돌아올 분깃을 내게 주소서 하는지라 아버지가 그 살림을 각각 나눠 주었더니\n13  그 후 며칠이 안 되어 둘째 아들이 재물을 다 모아 가지고 먼 나라에 가 거기서 허랑방탕하여 그 재산을 낭비하더니\n14  다 없앤 후 그 나라에 크게 흉년이 들어 그가 비로소 궁핍한지라\n15  가서 그 나라 백성 중 한 사람에게 붙여 사니 그가 그를 들로 보내어 돼지를 치게 하였는데\n16  그가 돼지 먹는 쥐엄 열매로 배를 채우고자 하되 주는 자가 없는지라\n17  이에 스스로 돌이켜 이르되 내 아버지에게는 양식이 풍족한 품꾼이 얼마나 많은가 나는 여기서 주려 죽는구나\n18  내가 일어나 아버지께 가서 이르기를 아버지 내가 하늘과 아버지께 죄를 지었사오니\n19  지금부터는 아버지의 아들이라 일컬음을 감당하지 못하겠나이다 나를 품꾼의 하나로 보소서 하리라 하고\n20  이에 일어나서 아버지께로 돌아가니라 아직도 거리가 먼데 아버지가 그를 보고 측은히 여겨 달려가 목을 안고 입을 맞추니\n21  아들이 이르되 아버지 내가 하늘과 아버지께 죄를 지었사오니 지금부터는 아버지의 아들이라 일컬음을 감당하지 못하겠나이다 <a href=\"https://www.bskorea.or.kr/bible/korbibReadpage.php?linkBible=BGAEluk015001#\">2)</a>하나\n22  아버지는 종들에게 이르되 제일 좋은 옷을 내어다가 입히고 손에 가락지를 끼우고 발에 신을 신기라\n23  그리고 살진 송아지를 끌어다가 잡으라 우리가 먹고 즐기자\n24  이 내 아들은 죽었다가 다시 살아났으며 내가 잃었다가 다시 얻었노라 하니 그들이 즐거워하더라\n25  맏아들은 밭에 있다가 돌아와 집에 가까이 왔을 때에 풍악과 춤추는 소리를 듣고\n26  한 종을 불러 이 무슨 일인가 물은대\n27  대답하되 당신의 동생이 돌아왔으매 당신의 아버지가 건강한 그를 다시 맞아들이게 됨으로 인하여 살진 송아지를 잡았나이다 하니\n28  그가 노하여 들어가고자 하지 아니하거늘 아버지가 나와서 권한대\n29  아버지께 대답하여 이르되 내가 여러 해 아버지를 섬겨 명을 어김이 없거늘 내게는 염소 새끼라도 주어 나와 내 벗으로 즐기게 하신 일이 없더니\n30  아버지의 살림을 창녀들과 함께 삼켜 버린 이 아들이 돌아오매 이를 위하여 살진 송아지를 잡으셨나이다\n31  아버지가 이르되 얘 너는 항상 나와 함께 있으니 내 것이 다 네 것이로되\n32  이 네 동생은 죽었다가 살아났으며 내가 잃었다가 얻었기로 우리가 즐거워하고 기뻐하는 것이 마땅하다 하니라</p>\n<h2 id=\"묵상문\" style=\"position:relative;\"><a href=\"#%EB%AC%B5%EC%83%81%EB%AC%B8\" aria-label=\"묵상문 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>묵상문</h2>\n<p>누가복음 15장에 나오는 세 비유(잃어버린 양을 찾은 목자, 잃어버린 드라크마를 찾은 여인, 잃어버린 아들을 찾은 아버지)를 통해 하나님 아버지께서 우리가 돌아오는 날을 기다리고 계시며, 우리가 돌아오는 순간 크게 기뻐하실 것을 알 수 있습니다.</p>\n<p>이 비유들을 처음에 들었을 때는, “나는 애초에 기독교를 믿지 않았으니, 이 비유는 나보다는 과거에는 기독교를 믿었지만 현재는 믿지 않는 사람들을 위한 구절인가”라고 생각했습니다. 그러나 이틀동안 계속해서 생각해보니, 내 입장에서는 하나님을 원래 몰랐으니 하나님께 돌아간다기보다는 그냥 처음 가는 것이라 느낄 수 있지만, 하나님 입장에서는 다르겠다고 생각하게 되었습니다.</p>\n<p>태초에 하나님께서 인간을 창조하셨고 우리가 하나님의 주인이기 때문에 하나님께서는 하나님과 성경을 잘 알지 못하는 저조차도 기다리고 계신다고 생각하게 되었습니다.</p>\n<p>저는 아직 1년 채 되지 않아 교회를 다니기 시작했습니다. 불교 집안에서 자라 성경을 접해보지 못했고, 24살이 된 지금에서야 성경을 읽고 있습니다. 아직 신앙심이 부족하여 의심도 많이 들고 온전히 하나님을 믿지 못하지만, 하나님께서 기뻐하시며 저를 맞아주실 것을 알고 있기 때문에 늦은 시작이지만 지금부터라도 하나님을 더 알고 하나님의 자녀로 성장할 수 있도록 노력해야겠다고 생각하게 되었습니다.</p>","frontmatter":{"date":"August 03, 2023","title":"I-GBS 묵상문 (누가복음 15장)","categories":"bible","author":"DolmaengC","emoji":"🧢"},"fields":{"slug":"/Luke-15/"}},"site":{"siteMetadata":{"siteUrl":"https://dolmaengc.github.io/gatsby-blog","comments":{"utterances":{"repo":"DolmaengC/gatsby-blog"}}}}},"pageContext":{"slug":"/recoder/","nextSlug":"/TreeGen/","prevSlug":"/Luke-15/"}},"staticQueryHashes":["1073350324","1956554647","2938748437"]}