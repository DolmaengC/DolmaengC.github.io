{"componentChunkName":"component---src-templates-blog-template-js","path":"/TreeGen/","result":{"data":{"cur":{"id":"fb46d56b-d700-5a53-895c-233ea069b00c","html":"<h1 id=\"treegen-a-tree-based-transformer-architecture-for-code-generation\" style=\"position:relative;\"><a href=\"#treegen-a-tree-based-transformer-architecture-for-code-generation\" aria-label=\"treegen a tree based transformer architecture for code generation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TreeGen: A Tree-Based Transformer Architecture for Code Generation</h1>\n<p>**Zeyu Sun† **</p>\n<p>**Qihao Zhu† **</p>\n<p>**Yingfei Xiong∗† **</p>\n<p>**Yican Sun† Lili Mou‡ **</p>\n<p><strong>Lu Zhang†</strong></p>\n<h2 id=\"abstrct\" style=\"position:relative;\"><a href=\"#abstrct\" aria-label=\"abstrct permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ABSTRCT</h2>\n<p>코드 생성 시스템은 자연어 묘사를 인풋으로 프로그래밍 언어 코드를 생성한다.</p>\n<p>최신 기술들은 뉴럴 네트워크에 의존하는데 , 2가지 문제점이 있다.</p>\n<ol>\n<li>긴 의존성 문제\n<ul>\n<li>코드는 종종 멀리있는 코드 요소의 영향을 받는다.</li>\n</ul>\n</li>\n<li>모델링 구조\n<ul>\n<li>많은 구조적 정보를 가지고 있다.</li>\n</ul>\n</li>\n</ol>\n<p>TreeGen : 새로운 트리 기반 뉴럴 구조 (트렌스포머의 어텐션 메커니즘을 사용)</p>\n<p>벤치마크</p>\n<ul>\n<li>파이썬 벤치마크 : HearthStone</li>\n<li>semantic parsing 벤치마크 : ATIS, GEO</li>\n</ul>\n<h1 id=\"introduction\" style=\"position:relative;\"><a href=\"#introduction\" aria-label=\"introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>INTRODUCTION</h1>\n<p>코드 생성은 개발자들의 생산성을 향상시키기 위한 중요한 인공지능이다.</p>\n<p>Seq2Seq, Seq2Tree 모델 등 다양한 신경망 구조를 갖는다.</p>\n<p>최신 접근법은 문법 규칙의 sequence를 예측하는 코드를 생성하는 것이다.</p>\n<p>이 논문은 새로운 신경망 구조 (TreeGen)을 제안한다.</p>\n<p>TreeGen은 트렌스포머 구조를 제안하지만, 기존의 트렌스포머는 프로그램용으로 설계되어 있지 않았으며,</p>\n<p>트리 구조에 최적화 되어 있지 않다.</p>\n<p>최적화를 위해서는 그래프, 트리 기반의 컨볼루션 신경망 구조를 가져야 한다.</p>\n<p>TreeGen은 3부분으로 구성한다.</p>\n<ol>\n<li>\n<p>A natural language reader (encoder) : encode the text description.</p>\n</li>\n<li>\n<p>A AST reader (the first several transformer decoder blocks) :</p>\n<p>encode the previously generated partial code with the structural convolution sub-layers</p>\n</li>\n<li>\n<p>A decoder (the rest transformer decoder blocks) :</p>\n<p>combine the query and previous two encoders to predict the next grammer rule.</p>\n</li>\n</ol>\n<h2 id=\"treegen\" style=\"position:relative;\"><a href=\"#treegen\" aria-label=\"treegen permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>TreeGen</h2>\n<p>![스크린샷 2023-08-01 오후 2.22.20](/Users/choejunhyeog/Desktop/스크린샷 2023-08-01 오후 2.22.20.png)</p>\n<h3 id=\"1-grammar-rule-prediction\" style=\"position:relative;\"><a href=\"#1-grammar-rule-prediction\" aria-label=\"1 grammar rule prediction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. Grammar Rule Prediction</h3>\n<p>decomposed into several context-free grammar rules and parsed as an AST</p>\n<p>AST-based code generation could be thought of as expanding a non-terminal node by a grammar rule. This process is repeated until all leaf nodes are terminal.</p>\n<p>선주문 트래버스에 따라 오른쪽 상단 모서리에 표시된 AST를 생성하는 일련의 규칙을 얻을 수 있습니다.</p>\n<p>Formally, the probability can be factorized as the proba- bilities of the rules generating the code following the order.</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 9.444444444444445%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAZ0lEQVQI101M2wpAERD0/9/mCzyRyCUKJSRz2n06U9vONBeRUkIIATln7L0hpYQxBucckNdag7WWudaa9VoL7z3MOZnTJ9CO8N7DOceF/2ApBeT13jlIGaUUaq0YY+Deyx4daUKMER+TypbH1ZfKIgAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"1.png\"\n        title=\"1.png\"\n        src=\"/static/f55283156537a0436bd2e7ecaa41f66d/37523/1.png\"\n        srcset=\"/static/f55283156537a0436bd2e7ecaa41f66d/e9ff0/1.png 180w,\n/static/f55283156537a0436bd2e7ecaa41f66d/f21e7/1.png 360w,\n/static/f55283156537a0436bd2e7ecaa41f66d/37523/1.png 720w,\n/static/f55283156537a0436bd2e7ecaa41f66d/302a4/1.png 1080w,\n/static/f55283156537a0436bd2e7ecaa41f66d/5f652/1.png 1302w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p>our task is to train a model to calculate p(ri | NL input, pi )</p>\n<h3 id=\"2-nl-reader\" style=\"position:relative;\"><a href=\"#2-nl-reader\" aria-label=\"2 nl reader permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. NL Reader</h3>\n<p>The input description determines the functionality of the code.</p>\n<ol>\n<li>Tokenize input description into tokens.</li>\n<li>All the tokens and characters are represented as real-valued vectors n1, n2,…,nL and c1, c2, … , cs by embeddings.</li>\n</ol>\n<p>In summary, the NL reader has a few Transformer blocks</p>\n<p>of self-attention, the gating mechanism, and word convolu-</p>\n<p>tion. The natural language description is encoded as features y(NL), y(NL), · · · , y(NL).</p>\n<h3 id=\"3-input-text-representation\" style=\"position:relative;\"><a href=\"#3-input-text-representation\" aria-label=\"3 input text representation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3. Input Text Representation</h3>\n<h4 id=\"character-embedding\" style=\"position:relative;\"><a href=\"#character-embedding\" aria-label=\"character embedding permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Character Embedding</h4>\n<p>Similar words have similar characters (e.g. “program” and “programs”)</p>\n<p>a token by character embeddings with <strong>a fully-connected layer</strong></p>\n<p>![스크린샷 2023-08-01 오후 5.37.43](/Users/choejunhyeog/Desktop/스크린샷 2023-08-01 오후 5.37.43.png)</p>\n<p>W(c) are the weights and the character sequence is padded to a pre-defined maximum length M.</p>\n<p><strong>Layer normalization</strong></p>\n<p>이 벡터들은 NL reader로 넘어가고 <strong>gating sub-layer</strong>에서 워드 임베딩과 통합된다.</p>\n<h3 id=\"4-neural-structure-of-nl-reader\" style=\"position:relative;\"><a href=\"#4-neural-structure-of-nl-reader\" aria-label=\"4 neural structure of nl reader permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>4. Neural Structure of NL Reader</h3>\n<p>The NL reader is composed of a stack of blocks.</p>\n<p>Each block contains three different sub-layers (self-attention, gating mechanism, word convolution)</p>\n<h4 id=\"self-attention\" style=\"position:relative;\"><a href=\"#self-attention\" aria-label=\"self attention permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Self-Attention</h4>\n<p>Transformer’s architecture</p>\n<p>Multi-head attention (to capture long dependency information)</p>\n<ol>\n<li>Embedding by a look-up table</li>\n<li>position embeddings</li>\n<li>Variant (Dehghani et al.)[<a href=\"https://arxiv.org/abs/1807.03819\">https://arxiv.org/abs/1807.03819</a>]</li>\n<li>Compute the position embedding for the 4th word in the word in the bth Transformer block as</li>\n</ol>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 16.666666666666664%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAADCAYAAACTWi8uAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAl0lEQVQI1z2P0QqFIBBE/f/vK0GsyKxIrSyoh6KY2OFyhUV0Zs/OKvzOuq7w3qOqKuz7jhACrLWIMVJzzqHrOpRliaIoqIv/vm/255zRti3U+76QmqYJKSUCzvMktO973sdxECCaQAW+bRv/nuchUDyiKyE3TUPTPM+ctCwLxnGEMYYmect0SSQJtdZMPQwDruv6b1jXNT7N5eCnGOZARQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"34.png\"\n        title=\"34.png\"\n        src=\"/static/bd49c69e3c7fa5ba9ee0bff0e21393db/37523/34.png\"\n        srcset=\"/static/bd49c69e3c7fa5ba9ee0bff0e21393db/e9ff0/34.png 180w,\n/static/bd49c69e3c7fa5ba9ee0bff0e21393db/f21e7/34.png 360w,\n/static/bd49c69e3c7fa5ba9ee0bff0e21393db/37523/34.png 720w,\n/static/bd49c69e3c7fa5ba9ee0bff0e21393db/302a4/34.png 1080w,\n/static/bd49c69e3c7fa5ba9ee0bff0e21393db/1132d/34.png 1158w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h4 id=\"gating-mechanism\" style=\"position:relative;\"><a href=\"#gating-mechanism\" aria-label=\"gating mechanism permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Gating Mechanism</h4>\n<p>Self-attention에 의해 특징들이 계산된 후에, character 임베딩 정보와 통합한다.</p>\n<p>gating mechanism은 softmax를 베이스로 한다.</p>\n<h4 id=\"word-convolution\" style=\"position:relative;\"><a href=\"#word-convolution\" aria-label=\"word convolution permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Word Convolution</h4>\n<p>2개의 컨볼루션 레이어가 gating 메카니즘의 아웃풋에 적용된다.</p>\n<p>여기서 seperable convolution이 사용된다.</p>\n<ul>\n<li>seperable convolution은 파라미터가 적어서 학습이 쉽다.</li>\n</ul>\n<p>첫번째와 마지막 단어를 위해 zero padding을 추가한다.</p>\n<p>GELU 활성화 함수 사용</p>\n<h3 id=\"5-ast-reader\" style=\"position:relative;\"><a href=\"#5-ast-reader\" aria-label=\"5 ast reader permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>5. AST Reader</h3>\n<p>생성된 부분적 AST의 구조를 모델링하기 위해 AST reader를 만들었다.</p>\n<p>문법 규칙의 순서를 예측하여 생성하지만, 이 규칙들만으로는 프로그램에 대한 구체적인 그림이 부족하고 다음 규칙을 예측하기에는 불충분하다.</p>\n<p>-> AST reader가 예측된 정보와 트리구조를 포함한 heterogeneous 정보를 고려한다.</p>\n<p>이러한 프로그램별 정보를 통합하기 위해 먼저 코드를 일련의 규칙으로 표현한 다음 어텐션 메커니즘으로 규칙을 인코딩하고 마지막으로 트리 컨볼루션 레이어를 사용하여 각 노드의 인코딩된 표현을 조상과 결합합니다.</p>\n<h3 id=\"6-ast-representation\" style=\"position:relative;\"><a href=\"#6-ast-representation\" aria-label=\"6 ast representation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>6. AST Representation</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 27.77777777777778%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAABYlAAAWJQFJUiTwAAAA/0lEQVQY01VQ6YqGMAz0/V9tBVlR8frhjda23gjqfrNMwIUVxjRpMpOpE4YhCKUU5nnGNE2w1sq573tkWYZ1XVFVFYIgQFmW2LZNasuy/Js5jgMOGzjUti26rvvDOI5CmOe5xKIo4Pu+IE1TRFEk4CLDMKBpGhFw3kGCF2/k9zyPkHML1pIkwevI8zzEcSxnCvCefQ6Tt4m2SEg1Wtj3XTanJda4HYlc9wtZlgp8/xuu64rwfd9wjDHQWos6Fd8NCdphzljXtdhPkhxxnGEYNJSyGEcLpbTYva4LDn8kZYH2CebckCAZBY0hZhhzwtoTxhxQaofWO7btxOfzI0/0CwXHu1deAv0BAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"production-rule\"\n        title=\"production-rule\"\n        src=\"/static/e7b5cc0bc11ac5d28122b7c329270c0d/37523/production-rule.png\"\n        srcset=\"/static/e7b5cc0bc11ac5d28122b7c329270c0d/e9ff0/production-rule.png 180w,\n/static/e7b5cc0bc11ac5d28122b7c329270c0d/f21e7/production-rule.png 360w,\n/static/e7b5cc0bc11ac5d28122b7c329270c0d/37523/production-rule.png 720w,\n/static/e7b5cc0bc11ac5d28122b7c329270c0d/302a4/production-rule.png 1080w,\n/static/e7b5cc0bc11ac5d28122b7c329270c0d/07a9c/production-rule.png 1440w,\n/static/e7b5cc0bc11ac5d28122b7c329270c0d/c679a/production-rule.png 2460w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p><strong>Rule Sequence Embedding</strong></p>\n<ul>\n<li>규칙 정보를 인코딩하기 위해서 규칙 ID를 사용한다.</li>\n<li>규칙들을 table-lookup 임베딩으로 real-valued vectors로 나타낸다.</li>\n</ul>\n<p><strong>Rule Definition Encoding</strong></p>\n<ul>\n<li>위의 테이블 조회 임베딩은 문법 규칙을 원자 토큰으로 취급하고 규칙 내용의 정보를 잃습니다.</li>\n<li>이 문제를 완화하기 위해 규칙 정의의 인코딩으로 규칙 표현을 향상시킵니다.</li>\n</ul>\n<p><strong>Position and Depth Embeddings</strong></p>\n<p>Position embedding</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 8.333333333333332%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAACCAYAAABYBvyLAAAACXBIWXMAABYlAAAWJQFJUiTwAAAAcUlEQVQI11WOuwoFIRBD9/+/zkIr8Y2yCiKKiIWYixYXdqpDksnM473HGAMpJbTWUGuFtRbOucu9dxhjEGOEUgqEEDDGIKX863tvnFlr4TniWXzf9xbmnME5hxDicikFWmucwydLKb3enPM+EkL4FP4AKMyVjwqm6GgAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"4.png\"\n        title=\"4.png\"\n        src=\"/static/0597f682568693ed51f875d060c15793/37523/4.png\"\n        srcset=\"/static/0597f682568693ed51f875d060c15793/e9ff0/4.png 180w,\n/static/0597f682568693ed51f875d060c15793/f21e7/4.png 360w,\n/static/0597f682568693ed51f875d060c15793/37523/4.png 720w,\n/static/0597f682568693ed51f875d060c15793/302a4/4.png 1080w,\n/static/0597f682568693ed51f875d060c15793/b490f/4.png 1142w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3 id=\"7-neural-structure-of-ast-reader\" style=\"position:relative;\"><a href=\"#7-neural-structure-of-ast-reader\" aria-label=\"7 neural structure of ast reader permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>7. Neural Structure of AST Reader</h3>\n<p>four sub-layers (self-attention, gating mechanism, NL attention, tree convolution)</p>\n<p>residual connection except the layer of tree convolution</p>\n<p>layer normalization</p>\n<p><strong>Self-Attention</strong></p>\n<p>Transformer-like self-attention layer</p>\n<p>input : sum of the rule embedding, position embedding, dept embedding</p>\n<p>extract features</p>\n<p><strong>Gating Mechanism</strong></p>\n<p>Content-encoding rule representation</p>\n<p>Transformer-extracted features</p>\n<p><strong>NL Attention</strong></p>\n<p>Multi-head NL attention (similar to the Transformer decoder’s attention to its encoder)</p>\n<p><strong>Tree Convolution</strong></p>\n<h3 id=\"8-decoder\" style=\"position:relative;\"><a href=\"#8-decoder\" aria-label=\"8 decoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>8. Decoder</h3>\n<h3 id=\"9-training-and-inference\" style=\"position:relative;\"><a href=\"#9-training-and-inference\" aria-label=\"9 training and inference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>9. Training and Inference</h3>","excerpt":"TreeGen: A Tree-Based Transformer Architecture for Code Generation **Zeyu Sun† ** **Qihao Zhu† ** **Yingfei Xiong∗† ** **Yican Sun† Lili Mou‡ ** Lu Zhang† ABSTRCT 코드 생성 시스템은 자연어 묘사를 인풋으로 프로그래밍 언어 코드를 생성한다. 최신 기술들은 뉴럴 네트워크에 의존하는데 , 2가지 문제점이 있다. 긴 의존성 문제 코드는 종종 멀리있는 코드 요소의 영향을 받는다. 모델링 구조 많은 구조적 정보를 가지고 있다. TreeGen : 새로운 트리 기반 뉴럴 구조 (트렌스포머의 어텐션 메커니즘을 사용) 벤치마크 파이썬 벤치마크 : HearthStone semantic parsing 벤치마크 : ATIS, GEO INTRODUCTION 코드 생성은 개발자들의 생산성을 향상시키기 위한 중요한 인공지능이다. Seq2Seq, Seq2Tree 모델 등 다양한 신경망…","frontmatter":{"date":"August 02, 2023","title":"TreeGen","categories":"DL","author":"DolmaengC","emoji":"🧢"},"fields":{"slug":"/TreeGen/"}},"next":{"id":"0f638ce2-927e-57c1-bc06-ed62b112bed0","html":"<p><a href=\"https://dolmaengc.github.io/gatsby-starter-zoomkoding-introduction/\">blog</a>에 의하면 목록을 생성하려면\nindex.md 파일 마지막에</p>\n<p>이걸 추가하라해서 추가하니깐 404 error 발생</p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\">```toc```</code></pre></div>\n<p>-></p>\n<div class=\"gatsby-highlight\" data-language=\"text\"><pre class=\"language-text\"><code class=\"language-text\"># 제목 1\n## 제목 2\n### 제목 3\n#### 제목 4</code></pre></div>\n<h1 id=\"제목-1\" style=\"position:relative;\"><a href=\"#%EC%A0%9C%EB%AA%A9-1\" aria-label=\"제목 1 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>제목 1</h1>\n<h2 id=\"제목-2\" style=\"position:relative;\"><a href=\"#%EC%A0%9C%EB%AA%A9-2\" aria-label=\"제목 2 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>제목 2</h2>\n<h3 id=\"제목-3\" style=\"position:relative;\"><a href=\"#%EC%A0%9C%EB%AA%A9-3\" aria-label=\"제목 3 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>제목 3</h3>\n<h4 id=\"제목-4\" style=\"position:relative;\"><a href=\"#%EC%A0%9C%EB%AA%A9-4\" aria-label=\"제목 4 permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>제목 4</h4>\n<p>toc이 목록을 만들어주는데 #으로 만든 제목 기준인거 같다.\n그래서 #없는 index.md 파일에 넣으면 post 페이지 전체가 404 error 뜨는거였음ㅋㅋ</p>","frontmatter":{"date":"July 23, 2023","title":"ERROR 85901  GRAPHQL 목록 기능 추가 중 404 에러","categories":"blog","author":"DolmaengC","emoji":"🧢"},"fields":{"slug":"/index-in-blog-error/"}},"prev":{"id":"c22268de-e987-5be4-bcac-d6f9120cc4d8","html":"<h1 id=\"a-syntax-guided-edit-decoder-for-neural-program-repair\" style=\"position:relative;\"><a href=\"#a-syntax-guided-edit-decoder-for-neural-program-repair\" aria-label=\"a syntax guided edit decoder for neural program repair permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>A Syntax-Guided Edit Decoder for Neural Program Repair</h1>\n<p><strong>Qihao Zhu</strong>\nKey Laboratory of HCST, MoE DCST, Peking University Beijing, China <a href=\"mailto:Zhuqh@pku.edu.cn\">Zhuqh@pku.edu.cn</a></p>\n<p><strong>Zeyu Sun</strong>\nKey Laboratory of HCST, MoE DCST, Peking University Beijing, China <a href=\"mailto:szy_@pku.edu.cn\">szy_@pku.edu.cn</a></p>\n<p><strong>Yuan-an Xiao</strong>\nKey Laboratory of HCST, MoE DCST, Peking University Beijing, China <a href=\"mailto:xiaoyuanan@pku.edu.cn\">xiaoyuanan@pku.edu.cn</a></p>\n<p><strong>Wenjie Zhang</strong>\nKey Laboratory of HCST, MoE DCST, Peking University Beijing, China <a href=\"mailto:zhang_wen_jie@pku.edu.cn\">zhang_wen_jie@pku.edu.cn</a></p>\n<p><strong>Kang Yuan</strong>\nStony Brook University New York, US <a href=\"mailto:kang.yuan@stonybrook.edu\">kang.yuan@stonybrook.edu</a></p>\n<p><strong>Yingfei Xiong</strong></p>\n<p>Key Laboratory of HCST, MoE DCST, Peking University Beijing, China <a href=\"mailto:xiongyf@pku.edu.cn\">xiongyf@pku.edu.cn</a></p>\n<p><strong>Lu Zhang</strong>\nKey Laboratory of HCST, MoE DCST, Peking University Beijing, China <a href=\"mailto:zhanglucs@pku.edu.cn\">zhanglucs@pku.edu.cn</a></p>\n<p><strong>KEYWORDS</strong></p>\n<p>Automated program repair, Neural networks</p>\n<p><strong>ACM Reference Format:</strong></p>\n<p>Qihao Zhu, Zeyu Sun, Yuan-an Xiao, Wenjie Zhang, Kang Yuan, Yingfei Xiong, and Lu Zhang. 2021. A Syntax-Guided Edit Decoder for Neural Program Repair. In Proceedings of the 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engi- neering (ESEC/FSE ’21), August 23–28, 2021, Athens, Greece. ACM, New York, NY, USA, 13 pages. <a href=\"https://doi.org/10.1145/3468264.3468544\">https://doi.org/10.1145/3468264.3468544</a></p>\n<p><a href=\"https://dl.acm.org/doi/abs/10.1145/3468264.3468544?casa_token=7YNel2Xox8EAAAAA:6Exp9p20FNVhkgXEIy-PjW8BoPAF_23tte2da-A5xEXNKNbhGqZ9gGhM_kb5rpF11-wo0nqIng_LHfE\">Link</a></p>\n<h2 id=\"abstract\" style=\"position:relative;\"><a href=\"#abstract\" aria-label=\"abstract permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>ABSTRACT</h2>\n<h2 id=\"1-introduction\" style=\"position:relative;\"><a href=\"#1-introduction\" aria-label=\"1 introduction permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>1. INTRODUCTION</h2>\n<p>DL 기반 APR 접근 방식은 아직 기존 APR 접근 방식을 능가하지 못했습니다.</p>\n<p>우리는 기존의 DL 기반 APR 접근 방식이 APR에 대해 다른 인코더 아키텍처를 제안했지만 디코더 아키텍처가 표준 아키텍처로 남아 원래 결함이 있는 프로그램 조각을 대체하기 위해 토큰 시퀀스를 하나씩 생성한다는 것을 관찰했습니다. 이 표준 디코더를 사용하면 DL 기반 APR의 성능이 크게 제한됩니다. 여기서 우리는 세 가지 주요 제한 사항을 강조합니다.</p>\n<h3 id=\"limitation-1-including-syntactically-incorrect-programs-in-the-patch-space\" style=\"position:relative;\"><a href=\"#limitation-1-including-syntactically-incorrect-programs-in-the-patch-space\" aria-label=\"limitation 1 including syntactically incorrect programs in the patch space permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Limitation 1: Including syntactically incorrect programs in the patch space.</h3>\n<h3 id=\"limitation-2-inefficient-representation-of-small-edits\" style=\"position:relative;\"><a href=\"#limitation-2-inefficient-representation-of-small-edits\" aria-label=\"limitation 2 inefficient representation of small edits permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Limitation 2: Inefficient representation of small edits.</h3>\n<h3 id=\"limitation-3-not-being-able-to-generate-project-specific-identifiers\" style=\"position:relative;\"><a href=\"#limitation-3-not-being-able-to-generate-project-specific-identifiers\" aria-label=\"limitation 3 not being able to generate project specific identifiers permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Limitation 3: Not being able to generate project-specific identifiers.</h3>\n<h3 id=\"novelty-1-syntax-guided-edit-decoding-with-providerdecider-architecture\" style=\"position:relative;\"><a href=\"#novelty-1-syntax-guided-edit-decoding-with-providerdecider-architecture\" aria-label=\"novelty 1 syntax guided edit decoding with providerdecider architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Novelty 1: Syntax-Guided Edit Decoding with Provider/Decider Architecture</h3>\n<h3 id=\"novelty-2-placeholder-generation\" style=\"position:relative;\"><a href=\"#novelty-2-placeholder-generation\" aria-label=\"novelty 2 placeholder generation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>Novelty 2: Placeholder Generation</h3>\n<h2 id=\"2-edits\" style=\"position:relative;\"><a href=\"#2-edits\" aria-label=\"2 edits permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2. EDITS</h2>\n<p>The syntax and semantic of edits and their relations to providers</p>\n<h3 id=\"21-syntax-and-semantics-of-edits\" style=\"position:relative;\"><a href=\"#21-syntax-and-semantics-of-edits\" aria-label=\"21 syntax and semantics of edits permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.1 Syntax and Semantics of Edits</h3>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 73.88888888888889%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAABYlAAAWJQFJUiTwAAABw0lEQVQ4y3WTh47DQAhE9/8/LUrvvTcrUXpvnB7S+OxTDomss4aBGXD4fD72er1st9vZ5XIxjDv8/X7b/X73d9vt1k6nk12vV7vdbnFcMh4LPByPR8vn8zabzVKB5/PZNpuNlUolazabVqlUrFwuO6hMYCnA/X5vjUbDlstlCvBwOHixVqtlk8nEgSk8Ho9tOBx6sSSwA/LDCwCz2WyKDhJAF6BOp+OFoU0hTuTAkEY5wRL2fD7tr3FXq9W8YK/Xs3a77R3zjAyDwcCq1Wqsv1MmiQtVhyadisZ0OnV9deLQxheLhZ/kxYCIj37JALoicbVaeTB0oY9TkKlzJ+c/1IP9Y+v12gEZBuBoyJShx1koFJw6z/V63Yf1eDx+OyS53++7NnQo/ZCBRCVRILmXGhRdxx0yLS4VSFByyuqIIQAYRZEXRVNcm+EaauTfTEOhIM4XRddQA0RfDRha7oBW0CkWi67VfD53naCZyWT8jlVBDmKIZanplmdpmcvlnFlgqQnsdruezF7hBLPQUEPf0Wjk94BBm/8MCkd3TmQLrARgSiJYy8sys0baTQ0BDaEKfdHV+XVtRJuTjgBXAQpCk/38Zj/aMmuRfkqwMQAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"figure4.png\"\n        title=\"figure4.png\"\n        src=\"/static/5afead6a057be132bc80e1e81b5101e3/37523/figure4.png\"\n        srcset=\"/static/5afead6a057be132bc80e1e81b5101e3/e9ff0/figure4.png 180w,\n/static/5afead6a057be132bc80e1e81b5101e3/f21e7/figure4.png 360w,\n/static/5afead6a057be132bc80e1e81b5101e3/37523/figure4.png 720w,\n/static/5afead6a057be132bc80e1e81b5101e3/302a4/figure4.png 1080w,\n/static/5afead6a057be132bc80e1e81b5101e3/105d8/figure4.png 1170w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<ul>\n<li>Host language : 별도의 소프트웨어가 설치되어 있지 않은 컴퓨터에서도 사용할 수 있는 프로그래밍 언어. 일반적으로 컴퓨터에서 사용되는 기계어가 이에 해당한다고 할 수 있지만, 몇몇 컴퓨터에서는 운영 체제에서 지원하는 고급 언어를 이 언어로 제공하고 있다.</li>\n<li>Non-terminal symbol : &#x3C;>로 둘러쌓인 기호를 논터미널 기호라고 부른다.</li>\n</ul>\n<p>Recoder는 특정 프로그래밍이 아닌 모든 프로그래밍 언어에 적용할 수 있다. (Host Language)</p>\n<p><strong>Rule 1</strong></p>\n<ul>\n<li>Edits은 Edits, Edit, end가 될 수 있다.</li>\n</ul>\n<p><strong>Rule 2</strong></p>\n<ul>\n<li>Edit은 Insert 혹은 Modift operation이다.</li>\n</ul>\n<p><strong>Rule 3</strong> (the syntax of insert operation)</p>\n<ul>\n<li>Insert operation은 faulty statement 앞에 새로운 statement를 생성한다.</li>\n<li>Insert operation has one parameter\n<ul>\n<li>HLStatement\n<ul>\n<li>non-terminal in the grammar of the host language that represents a statement\n<ul>\n<li>Non-terminal could be expanded into a full statement or copy operation</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong>Rule 4</strong> (the syntax of modify operation)</p>\n<ul>\n<li>Modify operation은 faulty statement를 가진 AST subtree를 새로운 AST subtree로 바꾼다.</li>\n<li>Modify operation has two parameter\n<ul>\n<li>First parameter : 교체될 AST subtree로부터의 root node의 ID\n<ul>\n<li>ID는 pre-order traveral sequence의 노드 순서로 정의된다.\n<ul>\n<li>6번째로 방문한 노드는 ID 6</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Second parameter : an AST subtree whose root node has the same symbol\n<ul>\n<li>the replacement ensures syntactic correctness</li>\n<li>the subtree to be replaced should have more than one node</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong>Rule 5</strong></p>\n<ul>\n<li>a meta-rule applied to any non-terminal symbol of the host language.</li>\n<li>add production rule that expands it into a copy operation</li>\n<li>the nueral network could choose to directly gerate a new subtree or to copy one</li>\n<li>For both insert and modify, they generate a new AST subtree\n<ul>\n<li>the AST subtree being inserted or modified is not completely original\n<ul>\n<li>Copy operation is introduced to further reduce the patch space</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>copy operation\n<ul>\n<li>1 parameter identifies the root node of the AST subtree to be copied\n<ul>\n<li>the faulty statement or its context</li>\n<li>method surrounding the faulty statement</li>\n</ul>\n</li>\n<li>the root node of the subtree to be copied should have the same non-terminal symbol as the symbol being extended</li>\n</ul>\n</li>\n</ul>\n<p>**Rule 6 **(placeholder)</p>\n<ul>\n<li>to generate concrete identifiers</li>\n<li>change identifier nodes into non-terminals</li>\n<li>plceholder or one of the frequent identifiers in the training set</li>\n</ul>\n<h3 id=\"23-generation-of-edits\" style=\"position:relative;\"><a href=\"#23-generation-of-edits\" aria-label=\"23 generation of edits permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>2.3 Generation of Edits</h3>\n<p>Providers : provide choices and estimate their probabilities</p>\n<p>3 type of providers</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 34.44444444444444%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAABYlAAAWJQFJUiTwAAABC0lEQVQoz12R6aqDQAyFff8H85+KiuJW9+IudUXUmnJSRnqvcMgkTk6+mZHo35emKVmWTUVRUBiG5HkexXHM6yRJWEEQkOM4/O+6rj/90nme1Pc9tW3LMcuyW1EUsZEwgzFqGJrnOT2fTxrHkaZpYh3HQRImYKIsy6QoCk99vV5kWRbpuk6GYXAEkaZppKoqm23bRuu60jAMt/Z9/xJigyCq65rmeWYi1EGFdVmW5Ps+C8TIBTWI0f9+v7+G2ASCx+PBZLg/5LZt07IsfBwMAQXoEVETEceG+MgwdF2XjUzTZLOmabiGHNcBgQjmMIbEkN94G+JBYIImMRk5hCuoqoq6rrtpxCP8ShB+APvoCZYgf0ngAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"table1.png\"\n        title=\"table1.png\"\n        src=\"/static/4bfd86434d0280fab4b0aa74b8b93eb9/37523/table1.png\"\n        srcset=\"/static/4bfd86434d0280fab4b0aa74b8b93eb9/e9ff0/table1.png 180w,\n/static/4bfd86434d0280fab4b0aa74b8b93eb9/f21e7/table1.png 360w,\n/static/4bfd86434d0280fab4b0aa74b8b93eb9/37523/table1.png 720w,\n/static/4bfd86434d0280fab4b0aa74b8b93eb9/302a4/table1.png 1080w,\n/static/4bfd86434d0280fab4b0aa74b8b93eb9/393aa/table1.png 1190w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<p><strong>rule predictor</strong></p>\n<ul>\n<li>선택 사항을 제공하고 각 production rule의 확률을 계산</li>\n<li>Neural component\n<ul>\n<li>각 생성 규칙에 대한 확률을 할당</li>\n</ul>\n</li>\n<li>Logic component\n<ul>\n<li>왼쪽이 해당 non-terminal이 아닌 rule의 확률을 0으로 재설정</li>\n<li>나머지 확률을 정규화</li>\n</ul>\n</li>\n</ul>\n<p><strong>subtree locator</strong></p>\n<ul>\n<li>선택 사항을 제공</li>\n<li>Faulty statement에서 크기가 1보다 큰 각 AST 하위 트리의 확률을 추정</li>\n</ul>\n<p><strong>tree copier</strong></p>\n<ul>\n<li>선택 사항 제공</li>\n<li>Faulty statement를 둘라싼 method의 크기가 1보다 큰 각 AST subtree의 확률을 추정</li>\n<li>neural component</li>\n<li>logic component\n<ul>\n<li>root symbol이 확장되는 non-terminal symbol과 다른 subtree의 확룰을 재설정</li>\n</ul>\n</li>\n</ul>\n<p><strong>decider</strong></p>\n<ul>\n<li>각 provider에 확률을 할당</li>\n<li>similar logic component\n<ul>\n<li>provider가 현재 non-terminal symbol을 담당하지 않을 경우, 확률을 0으로 재설정</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"3-model-architecture\" style=\"position:relative;\"><a href=\"#3-model-architecture\" aria-label=\"3 model architecture permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3 MODEL ARCHITECTURE</h2>\n<p>Recoder is based on the syntax guided code generation model, <a href=\"https://ojs.aaai.org/index.php/AAAI/article/view/6430\">TreeGen</a></p>\n<p>input : a faulty statement and its comtext</p>\n<p>output : edits</p>\n<p>Beam search (to find the best combination of choices for generating the complete edits)</p>\n<p>4 main component</p>\n<ul>\n<li>code reader</li>\n<li>AST reader</li>\n<li>tree path reader</li>\n<li>Edit decoder</li>\n</ul>\n<p>AST reader, tree path reader : TreeGen</p>\n<p>Code reader, edit decoder : newly introduced</p>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 32.22222222222222%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAABYlAAAWJQFJUiTwAAABRUlEQVQY0z1RTWvCQBDNH++5v6HY2oLHHrQkMd+fNWmTkEMa2SAoCB7UVASDURDjKzNgB5adefvmzTJPatsWq9UK0+kUy+US+/2eD2FUb7dbXK9XUDRNg+PxiHt0XYfb7cb3PaSiKKBpGkzThOu6iOMYvu/Dsqx/bLFYIIoiBEHAb3meI80yaJoB3TChjjU4roe2PUFK05QbScDzPBbXdR2O4zBGOeGqqmI4HEKWFfiei/7gHQ+PT+g99/HW72Hw+oK6/oWUZRlPpib6xWg0gizLLESCNMC2bYRhyLzvJEEQ+PiQx7D9LxiWgzD8ZM5ut4NUVRWTCTAMgw/VNIAwRVGQJAlo8GQy4RUQnqYJyp+CMSEqCCF4vxItlZL5fI7NZoPL5YLz+cymlGWJ9XrNJtV1zU2z2Yz5zeGAOIpQCcHmEY9M+QN6g5p5TiMDIwAAAABJRU5ErkJggg=='); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"figure7.png\"\n        title=\"figure7.png\"\n        src=\"/static/592d4ccd9b7044beb668312034b0f6b6/37523/figure7.png\"\n        srcset=\"/static/592d4ccd9b7044beb668312034b0f6b6/e9ff0/figure7.png 180w,\n/static/592d4ccd9b7044beb668312034b0f6b6/f21e7/figure7.png 360w,\n/static/592d4ccd9b7044beb668312034b0f6b6/37523/figure7.png 720w,\n/static/592d4ccd9b7044beb668312034b0f6b6/302a4/figure7.png 1080w,\n/static/592d4ccd9b7044beb668312034b0f6b6/07a9c/figure7.png 1440w,\n/static/592d4ccd9b7044beb668312034b0f6b6/4a70a/figure7.png 2390w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></p>\n<h3 id=\"31-code-reader\" style=\"position:relative;\"><a href=\"#31-code-reader\" aria-label=\"31 code reader permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.1 Code Reader</h3>\n<p>input</p>\n<ul>\n<li>AST traversal sequence\n<ul>\n<li>a sequence of tokens following the pre-order traversal of the AST</li>\n<li>word embedding</li>\n</ul>\n</li>\n<li>Tag embedding\n<ul>\n<li>Pre-order traversal of the AST</li>\n<li>tag\n<ol>\n<li>in the faulty statement</li>\n<li>In the statement before the faulty statement</li>\n<li>In the statement after the faulty statement</li>\n<li>in other statements</li>\n</ol>\n</li>\n</ul>\n</li>\n<li>AST-based Graph\n<ul>\n<li>directional graph where the nodes are AST nodes and the edges link a node to each of its children and its sibling</li>\n<li><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 720px; \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 38.888888888888886%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAABYlAAAWJQFJUiTwAAABMklEQVQoz31Ra4+CQAzk//8vEEMiMchbI6DyUCQ+QA0Exkwv68UPd5s0dOnsdDrVpmkCT9d1uF6vuN1uuN/vEuM4So0YhXs+n1845sMwfHCaAmZZBl3XMZvNJDzPE6Cqq9M0DebzOQzDgGmaWCwWaNv2l5AAx3Hg+z7KsoTrutjtdhJBEKCuaxRFIbXtdgvbtuW7Xq8RhiGSJBFcnuciQOMDgqjwdDoJ4eFwECLmBHJMqiABm7MWxzGiKBLFzBlCeD6fsVqtkKYpqqqCHwTY7/dCtFwupZHyjgS04ng8isLNZiPknI4qhRB/HDYiiKr/O1wmm5C87/ufpSjjL5eLeMLNKRX0kneORjUM5vxPb1+vl9S58c+WFSGNtyxLTOcDjsKxaQcV8E4fqVwt6PF4fCl+Az8tVqpYcGPXAAAAAElFTkSuQmCC'); background-size: cover; display: block;\"\n  ></span>\n  <img\n        class=\"gatsby-resp-image-image\"\n        alt=\"figure8.png\"\n        title=\"figure8.png\"\n        src=\"/static/d4383fd3c116d749d45bacf6e9816fc7/37523/figure8.png\"\n        srcset=\"/static/d4383fd3c116d749d45bacf6e9816fc7/e9ff0/figure8.png 180w,\n/static/d4383fd3c116d749d45bacf6e9816fc7/f21e7/figure8.png 360w,\n/static/d4383fd3c116d749d45bacf6e9816fc7/37523/figure8.png 720w,\n/static/d4383fd3c116d749d45bacf6e9816fc7/302a4/figure8.png 1080w,\n/static/d4383fd3c116d749d45bacf6e9816fc7/df56e/figure8.png 1188w\"\n        sizes=\"(max-width: 720px) 100vw, 720px\"\n        style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n        loading=\"lazy\"\n        decoding=\"async\"\n      />\n    </span></li>\n</ul>\n</li>\n</ul>\n<h4 id=\"311-self-attention\" style=\"position:relative;\"><a href=\"#311-self-attention\" aria-label=\"311 self attention permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.1.1 Self-Attention</h4>\n<ul>\n<li>self-attention sub-layer\n<ul>\n<li>encoding the AST traversal sequence</li>\n<li><a href=\"https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html\">Transformer</a> architecture\n<ul>\n<li>Capture the long dependency information in the AST</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>Position embedding (represent positional information)</li>\n<li>multi-head attention layer\n<ul>\n<li>capture non-linear features</li>\n<li>The single attention layer maps the query Q, the key K, and the value V into a weighted-sum output</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"312-gating-layer\" style=\"position:relative;\"><a href=\"#312-gating-layer\" aria-label=\"312 gating layer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.1.2 Gating Layer</h4>\n<ul>\n<li>input : self-attention 레이어의 아웃풋 + 태그 임베딩</li>\n<li>TreeGen에서 정의된 Gating mechanism이 이 레이어에서 사용되었다.</li>\n</ul>\n<h4 id=\"313-tree-conv-layer\" style=\"position:relative;\"><a href=\"#313-tree-conv-layer\" aria-label=\"313 tree conv layer permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.1.3 Tree Conv Layer</h4>\n<ul>\n<li>\n<p>input : gating layer의 아웃풋 + AST-based graph</p>\n</li>\n<li>\n<p>GNN layer</p>\n</li>\n<li>\n<p>encode the neighbors</p>\n</li>\n</ul>\n<h3 id=\"32-ast-reader\" style=\"position:relative;\"><a href=\"#32-ast-reader\" aria-label=\"32 ast reader permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.2 AST Reader</h3>\n<ul>\n<li>Encode the partial generated AST of the edit (TreeGen)</li>\n<li>Rule requence\n<ul>\n<li>represented as real-value vectors</li>\n<li>fed into a self-attention layer</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"33-tree-path-reader\" style=\"position:relative;\"><a href=\"#33-tree-path-reader\" aria-label=\"33 tree path reader permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.3 Tree Path Reader</h3>\n<ul>\n<li>Encode the information of the non-terminal node to be expanded (TreeGen)</li>\n<li>Represent the non-terminal node as a path from the root to the node to be expanded</li>\n<li>Transforms the nodes in this path into real-value vectors</li>\n<li>Two fully-connected layers are followed to extract features for edit decoder</li>\n</ul>\n<h3 id=\"34-edit-decoder\" style=\"position:relative;\"><a href=\"#34-edit-decoder\" aria-label=\"34 edit decoder permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.4 Edit Decoder</h3>\n<p>Input : tree path reader의 아웃풋</p>\n<p>output : the probability of choices for diferent non-terminals</p>\n<h4 id=\"341-provider\" style=\"position:relative;\"><a href=\"#341-provider\" aria-label=\"341 provider permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.4.1 Provider</h4>\n<p><strong>Rule Predictor</strong></p>\n<ul>\n<li>Estimate the probability of each production rule in the grammar of edits</li>\n<li>Nueral component (a fully-connected layer)</li>\n<li>Normalized via softmax</li>\n<li>Invalid rules whose left-hand side is not the corresponding non-terminal are not allowed</li>\n<li>The logic component resets the output of the fully-connected layer to -∞.</li>\n</ul>\n<p><strong>Tree Copier</strong></p>\n<ul>\n<li>Designed for any non-terminal symbol in the grammer of edits to choose a subtree in the local context</li>\n<li>Nueral component (a pointer network)</li>\n<li>The logic component resets  𝜽 to −∞ if the root symbol of the corresponding subtree is different from the symbol being expanded.</li>\n<li>Normalized via softmax</li>\n</ul>\n<p><strong>Subtree Locator</strong></p>\n<p>output : an ID of the subtree in the faulty statement for not-terminal symbol, Modify, in the grammar of edits.</p>\n<h4 id=\"342-decider\" style=\"position:relative;\"><a href=\"#342-decider\" aria-label=\"342 decider permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.4.2 Decider</h4>\n<ul>\n<li>Estimate the probability of using each provider</li>\n<li>Neural component\n<ul>\n<li>input : the output of the tree path reader</li>\n<li>output : the probability of using each provider</li>\n<li>A fully-connected layer</li>\n</ul>\n</li>\n<li>Logic component resets 𝝀 to −∞ if the corresponding provider is not responsible for the symbol being expanded following Table 1.</li>\n<li>Normalized via softmax</li>\n</ul>\n<h3 id=\"35-training-and-inference\" style=\"position:relative;\"><a href=\"#35-training-and-inference\" aria-label=\"35 training and inference permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.5 Training and Inference</h3>\n<h3 id=\"36-patch-generation-and-validation\" style=\"position:relative;\"><a href=\"#36-patch-generation-and-validation\" aria-label=\"36 patch generation and validation permalink\" class=\"anchor before\"><svg aria-hidden=\"true\" focusable=\"false\" height=\"16\" version=\"1.1\" viewBox=\"0 0 16 16\" width=\"16\"><path fill-rule=\"evenodd\" d=\"M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z\"></path></svg></a>3.6 Patch Generation and Validation</h3>","frontmatter":{"date":"August 03, 2023","title":"Recoder (A Syntax-guided Edit Decoder for Neural Program Repair)","categories":"APR featured","author":"DolmaengC","emoji":"🧢"},"fields":{"slug":"/recoder/"}},"site":{"siteMetadata":{"siteUrl":"https://dolmaengc.github.io/gatsby-blog","comments":{"utterances":{"repo":"DolmaengC/gatsby-blog"}}}}},"pageContext":{"slug":"/TreeGen/","nextSlug":"/index-in-blog-error/","prevSlug":"/recoder/"}},"staticQueryHashes":["1073350324","1956554647","2938748437"]}