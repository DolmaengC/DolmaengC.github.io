---
emoji: ğŸ§¢
title: Recoder (A Syntax-guided Edit Decoder for Neural Program Repair)
date: '2023-08-03 22:00:00'
author: DolmaengC
tags: APR 
categories: APR featured
---



# A Syntax-Guided Edit Decoder for Neural Program Repair

**Qihao Zhu**
 Key Laboratory of HCST, MoE DCST, Peking University Beijing, China Zhuqh@pku.edu.cn

**Zeyu Sun**
 Key Laboratory of HCST, MoE DCST, Peking University Beijing, China szy_@pku.edu.cn

**Yuan-an Xiao**
 Key Laboratory of HCST, MoE DCST, Peking University Beijing, China xiaoyuanan@pku.edu.cn

**Wenjie Zhang**
 Key Laboratory of HCST, MoE DCST, Peking University Beijing, China zhang_wen_jie@pku.edu.cn

**Kang Yuan**
 Stony Brook University New York, US kang.yuan@stonybrook.edu

**Yingfei Xiong**

Key Laboratory of HCST, MoE DCST, Peking University Beijing, China xiongyf@pku.edu.cn

**Lu Zhang**
 Key Laboratory of HCST, MoE DCST, Peking University Beijing, China zhanglucs@pku.edu.cn



**KEYWORDS**

Automated program repair, Neural networks



**ACM Reference Format:**

Qihao Zhu, Zeyu Sun, Yuan-an Xiao, Wenjie Zhang, Kang Yuan, Yingfei Xiong, and Lu Zhang. 2021. A Syntax-Guided Edit Decoder for Neural Program Repair. In Proceedings of the 29th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engi- neering (ESEC/FSE â€™21), August 23â€“28, 2021, Athens, Greece. ACM, New York, NY, USA, 13 pages. https://doi.org/10.1145/3468264.3468544



[Link](https://dl.acm.org/doi/abs/10.1145/3468264.3468544?casa_token=7YNel2Xox8EAAAAA:6Exp9p20FNVhkgXEIy-PjW8BoPAF_23tte2da-A5xEXNKNbhGqZ9gGhM_kb5rpF11-wo0nqIng_LHfE)



## ABSTRACT





## 1. INTRODUCTION

DL ê¸°ë°˜ APR ì ‘ê·¼ ë°©ì‹ì€ ì•„ì§ ê¸°ì¡´ APR ì ‘ê·¼ ë°©ì‹ì„ ëŠ¥ê°€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.

ìš°ë¦¬ëŠ” ê¸°ì¡´ì˜ DL ê¸°ë°˜ APR ì ‘ê·¼ ë°©ì‹ì´ APRì— ëŒ€í•´ ë‹¤ë¥¸ ì¸ì½”ë” ì•„í‚¤í…ì²˜ë¥¼ ì œì•ˆí–ˆì§€ë§Œ ë””ì½”ë” ì•„í‚¤í…ì²˜ê°€ í‘œì¤€ ì•„í‚¤í…ì²˜ë¡œ ë‚¨ì•„ ì›ë˜ ê²°í•¨ì´ ìˆëŠ” í”„ë¡œê·¸ë¨ ì¡°ê°ì„ ëŒ€ì²´í•˜ê¸° ìœ„í•´ í† í° ì‹œí€€ìŠ¤ë¥¼ í•˜ë‚˜ì”© ìƒì„±í•œë‹¤ëŠ” ê²ƒì„ ê´€ì°°í–ˆìŠµë‹ˆë‹¤. ì´ í‘œì¤€ ë””ì½”ë”ë¥¼ ì‚¬ìš©í•˜ë©´ DL ê¸°ë°˜ APRì˜ ì„±ëŠ¥ì´ í¬ê²Œ ì œí•œë©ë‹ˆë‹¤. ì—¬ê¸°ì„œ ìš°ë¦¬ëŠ” ì„¸ ê°€ì§€ ì£¼ìš” ì œí•œ ì‚¬í•­ì„ ê°•ì¡°í•©ë‹ˆë‹¤.



### Limitation 1: Including syntactically incorrect programs in the patch space.



### Limitation 2: Inefficient representation of small edits.



### Limitation 3: Not being able to generate project-specific identifiers.



### Novelty 1: Syntax-Guided Edit Decoding with Provider/Decider Architecture



### Novelty 2: Placeholder Generation



## 2. EDITS

The syntax and semantic of edits and their relations to providers



### 2.1 Syntax and Semantics of Edits

![figure4.png](figure4.png)

* Host language : ë³„ë„ì˜ ì†Œí”„íŠ¸ì›¨ì–´ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•Šì€ ì»´í“¨í„°ì—ì„œë„ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í”„ë¡œê·¸ë˜ë° ì–¸ì–´. ì¼ë°˜ì ìœ¼ë¡œ ì»´í“¨í„°ì—ì„œ ì‚¬ìš©ë˜ëŠ” ê¸°ê³„ì–´ê°€ ì´ì— í•´ë‹¹í•œë‹¤ê³  í•  ìˆ˜ ìˆì§€ë§Œ, ëª‡ëª‡ ì»´í“¨í„°ì—ì„œëŠ” ìš´ì˜ ì²´ì œì—ì„œ ì§€ì›í•˜ëŠ” ê³ ê¸‰ ì–¸ì–´ë¥¼ ì´ ì–¸ì–´ë¡œ ì œê³µí•˜ê³  ìˆë‹¤.
* Non-terminal symbol : <>ë¡œ ë‘˜ëŸ¬ìŒ“ì¸ ê¸°í˜¸ë¥¼ ë…¼í„°ë¯¸ë„ ê¸°í˜¸ë¼ê³  ë¶€ë¥¸ë‹¤.



RecoderëŠ” íŠ¹ì • í”„ë¡œê·¸ë˜ë°ì´ ì•„ë‹Œ ëª¨ë“  í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— ì ìš©í•  ìˆ˜ ìˆë‹¤. (Host Language)



**Rule 1**

- Editsì€ Edits, Edit, endê°€ ë  ìˆ˜ ìˆë‹¤.

**Rule 2**

- Editì€ Insert í˜¹ì€ Modift operationì´ë‹¤.

**Rule 3** (the syntax of insert operation)

- Insert operationì€ faulty statement ì•ì— ìƒˆë¡œìš´ statementë¥¼ ìƒì„±í•œë‹¤.
- Insert operation has one parameter
  - HLStatement
    - non-terminal in the grammar of the host language that represents a statement
      - Non-terminal could be expanded into a full statement or copy operation

**Rule 4** (the syntax of modify operation)

- Modify operationì€ faulty statementë¥¼ ê°€ì§„ AST subtreeë¥¼ ìƒˆë¡œìš´ AST subtreeë¡œ ë°”ê¾¼ë‹¤.
- Modify operation has two parameter
  - First parameter : êµì²´ë  AST subtreeë¡œë¶€í„°ì˜ root nodeì˜ ID
    - IDëŠ” pre-order traveral sequenceì˜ ë…¸ë“œ ìˆœì„œë¡œ ì •ì˜ëœë‹¤.
      - 6ë²ˆì§¸ë¡œ ë°©ë¬¸í•œ ë…¸ë“œëŠ” ID 6
  - Second parameter : an AST subtree whose root node has the same symbol
    - the replacement ensures syntactic correctness
    - the subtree to be replaced should have more than one node

**Rule 5**

- a meta-rule applied to any non-terminal symbol of the host language.
- add production rule that expands it into a copy operation
- the neural network could choose to directly gerate a new subtree or to copy one
- For both insert and modify, they generate a new AST subtree
  - the AST subtree being inserted or modified is not completely original
    - Copy operation is introduced to further reduce the patch space
- copy operation
  - 1 parameter identifies the root node of the AST subtree to be copied
    - the faulty statement or its context
    - method surrounding the faulty statement
  - the root node of the subtree to be copied should have the same non-terminal symbol as the symbol being extended

**Rule 6 **(placeholder)

- to generate concrete identifiers
- change identifier nodes into non-terminals
- plceholder or one of the frequent identifiers in the training set



### 2.3 Generation of Edits

Providers : provide choices and estimate their probabilities

3 type of providers

![table1.png](table1.png)

**rule predictor**

- ì„ íƒ ì‚¬í•­ì„ ì œê³µí•˜ê³  ê° production ruleì˜ í™•ë¥ ì„ ê³„ì‚°
- Neural component 
  - ê° ìƒì„± ê·œì¹™ì— ëŒ€í•œ í™•ë¥ ì„ í• ë‹¹
- Logic component
  - ì™¼ìª½ì´ í•´ë‹¹ non-terminalì´ ì•„ë‹Œ ruleì˜ í™•ë¥ ì„ 0ìœ¼ë¡œ ì¬ì„¤ì •
  - ë‚˜ë¨¸ì§€ í™•ë¥ ì„ ì •ê·œí™”



**subtree locator**

- ì„ íƒ ì‚¬í•­ì„ ì œê³µ
- Faulty statementì—ì„œ í¬ê¸°ê°€ 1ë³´ë‹¤ í° ê° AST í•˜ìœ„ íŠ¸ë¦¬ì˜ í™•ë¥ ì„ ì¶”ì •



**tree copier**

- ì„ íƒ ì‚¬í•­ ì œê³µ
- Faulty statementë¥¼ ë‘˜ëŸ¬ì‹¼ methodì˜ í¬ê¸°ê°€ 1ë³´ë‹¤ í° ê° AST subtreeì˜ í™•ë¥ ì„ ì¶”ì •
- neural component
- logic component
  - root symbolì´ í™•ì¥ë˜ëŠ” non-terminal symbolê³¼ ë‹¤ë¥¸ subtreeì˜ í™•ë¥ ì„ ì¬ì„¤ì •



**decider**

- ê° providerì— í™•ë¥ ì„ í• ë‹¹
- similar logic component
  - providerê°€ í˜„ì¬ non-terminal symbolì„ ë‹´ë‹¹í•˜ì§€ ì•Šì„ ê²½ìš°, í™•ë¥ ì„ 0ìœ¼ë¡œ ì¬ì„¤ì •



## 3 MODEL ARCHITECTURE

Recoder is based on the syntax guided code generation model, [TreeGen](https://ojs.aaai.org/index.php/AAAI/article/view/6430)

input : a faulty statement and its comtext

output : edits

Beam search (to find the best combination of choices for generating the complete edits)

4 main component

- code reader
- AST reader
- tree path reader
- Edit decoder



AST reader, tree path reader : TreeGen

Code reader, edit decoder : newly introduced



![figure7.png](figure7.png)



### 3.1 Code Reader

input

- AST traversal sequence
  - a sequence of tokens following the pre-order traversal of the AST
  - word embedding
- Tag embedding
  - Pre-order traversal of the AST
  - tag
    1. in the faulty statement
    2. In the statement before the faulty statement
    3. In the statement after the faulty statement
    4. in other statements
- AST-based Graph
  - directional graph where the nodes are AST nodes and the edges link a node to each of its children and its sibling
  - ![figure8.png](figure8.png)



#### 3.1.1 Self-Attention

- self-attention sub-layer
  - encoding the AST traversal sequence
  - [Transformer](https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html) architecture
    - Capture the long dependency information in the AST
- Position embedding (represent positional information)
- multi-head attention layer
  - capture non-linear features
  - The single attention layer maps the query Q, the key K, and the value V into a weighted-sum output




#### 3.1.2 Gating Layer

- input : self-attention ë ˆì´ì–´ì˜ ì•„ì›ƒí’‹ + íƒœê·¸ ì„ë² ë”©
- output : ğ’–ğ‘– =Gating(ğ’‚ğ’Š,ğ’‚ğ’Š,ğ’•ğ‘–).
- TreeGenì—ì„œ ì •ì˜ëœ Gating mechanismì´ ì´ ë ˆì´ì–´ì—ì„œ ì‚¬ìš©ë˜ì—ˆë‹¤. (softmax ê¸°ë°˜)



#### 3.1.3 Tree Conv Layer

- input : gating layerì˜ ì•„ì›ƒí’‹ + AST-based graph

- output : The encoding of the neighbors is directly added to the input vector

- GNN layer
- encode the neighbors

![8.png](8.png)

- ğ‘Šg is the weigh of a fullt -connected layer and A is a normalized adjacency matrix of G



### 3.2 AST Reader

- Encode the partial generated AST of the edit (TreeGen)
- Rule sequence
  - represented as real-value vectors
  - fed into a self-attention layer



### 3.3 Tree Path Reader

- Encode the information of the non-terminal node to be expanded (TreeGen)
- Represent the non-terminal node as a path from the root to the node to be expanded
- Transforms the nodes in this path into real-value vectors
- Two fully-connected layers are followed to extract features for edit decoder



### 3.4 Edit Decoder

#### 3.4.1 Provider

- Input : tree path readerì˜ ì•„ì›ƒí’‹

- output : the probability of choices for different non-terminals



**Rule Predictor**

- Estimate the probability of each production rule in the grammar of edits
- Neural component (a fully-connected layer)
- Normalized via softmax
- Invalid rules whose left-hand side is not the corresponding non-terminal are not allowed
- The logic component resets the output of the fully-connected layer to -âˆ.



**Tree Copier**

- Designed for any non-terminal symbol in the grammer of edits to choose a subtree in the local context
- Neural component (a pointer network)
- The logic component resets  ğœ½ to âˆ’âˆ if the root symbol of the corresponding subtree is different from the symbol being expanded.
- Normalized via softmax



**Subtree Locator**

output : an ID of the subtree in the faulty statement for not-terminal symbol, Modify, in the grammar of edits.



#### 3.4.2 Decider

- Estimate the probability of using each provider
- Neural component
  - input : the output of the tree path reader
  - output : the probability of using each provider
  - A fully-connected layer
- Logic component resets ğ€ to âˆ’âˆ if the corresponding provider is not responsible for the symbol being expanded following Table 1.
- Normalized via softmax



## 5 EXPERIMENTAL RESULTS
![table2.png](table2.png)

---

![table3.png](table3.png)

---

![table4.png](table4.png)

---
![table5.png](table5.png)

---
![table6.png](table6.png)

---

















